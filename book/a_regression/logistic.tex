% The Clever Algorithms Project: http://www.CleverAlgorithms.com
% (c) Copyright 2011 Jason Brownlee. Some Rights Reserved. 
% This work is licensed under a Creative Commons Attribution-Noncommercial-Share Alike 2.5 Australia License.

% Name
% The algorithm name defines the canonical name used to refer to the technique, in addition to common aliases, abbreviations, and acronyms. The name is used in terms of the heading and sub-headings of an algorithm description.
\section{Logistic Regression} 
\label{sec:logistic}
\index{Logistic Regression}
\index{logit}

% other names
% What is the canonical name and common aliases for a technique?
% What are the common abbreviations and acronyms for a technique?
\emph{Logistic Regression, Logit, Logit Model, Logistic Model, Binomial Logistic Regression, Binary Logistic Regression}

% Taxonomy: Lineage and locality
\subsection{Taxonomy}
% To what fields of study does a technique belong?
% What are the closely related approaches to a technique?
Logistic Regression is a regression method from the field of statistics. 
The most common form is Binomial Logistic Regression where the dependent variable is binary.
Logistic Regression may be considered a special case of Generalized Linear Regression.
Logistic Regression has many extensions including Ordered Logistic Regression that can handle ordinal dependent variables, and Multinomial Logistic Regression that can handle nominal (categorical) dependant variables.

What is Weighted Logistic Regression?
What is Stepwise Logistic Regression?

% Strategy: Problem solving plan
% The strategy is an abstract description of the computational model. The strategy describes the information processing actions a technique shall take in order to achieve an objective. The strategy provides a logical separation between a computational realization (procedure) and a analogous system (metaphor). A given problem solving strategy may be realized as one of a number specific algorithms or problem solving systems. The strategy description is textual using information processing and algorithmic terminology.
\subsection{Strategy}
% What is the information processing objective of a technique?
Logistic Regression fits data to a logistic (sigmoidal) function and makes predictions of the probability of occurrence of an event. 
% What is a techniques plan of action?
A logistic function is used because it can take any values (positive or negative) and produce a value between 0 and 1. The logistic function is influenced by a logit function which take a variable derived from a sum of the weighted attributes. The logit function is the natural logarithm of the odds of the dependant variable equalling one.

The sign of a regression coefficient may be interpreted as the increase or decrease of an attribute to the resulting probability, and the magnitude represents the influence of the attribute.
The regression coefficients (weights) are fit by minimising the maximum likelihood loss function. The problem as a system of linear equations use the Conjugate Gradient Method to solve the coefficients. Much research into the method is focused on more efficient algorithms for fitting the model.


% help me use this technique
\subsection{Overview}

% what it is good at
\subsubsection{Features}

\begin{itemize}
	\item Generally fast to create and results in an explainable model.
	\item Generally not parametrized, so there are no parameters to configure. 
	\item Does not assume a linear relationship between the independent variables and the dependant variable. 
	\item Does not require normally distributed variables.
	\item The result is a probability of the occurrence of an event that may be interpreted as such and/or in turn be discretized to a binary classification prediction.
	\item More data can result in a better fit of the model.
	\item Training data with a minimum of 10 events per independent variable is recommended \cite{Peduzzi1996}.
	\item Features should be selected prior to fitting.
	\item Provides statistical test significance on a fitted model including: Wald Z-statistic, Likelihood-Ratio Test, and the Hosmer-Lemshow Goodness of Fit Test.
\end{itemize}

% what it is not good at
\subsubsection{Limitations}

\begin{itemize}
	\item The dependant variable must be binary (otherwise one must use another form of the method).
	\item The use of a logistic function means that input attributes can take any value, the bounds do not need to be known prior to building the model.
	\item It can only handle real-valued dependant variables.
	\item Dependent on the size of the sample used to prepare the model, smaller samples ($<1000$ or $<500$) can result in a model that overfits the training data.
	\item Solving the coefficients for large models can be very computationally expensive and remains an open area for research.
	\item Missing values must be handled explicitly or those records removed.
	\item Requires that the independent variable be related to the logit by a linear relationship.
\end{itemize}


% sample script in R
\subsection{Code Listing}
Listing~\ref{examplelogit} provides a code listing of Logistic Regression in R using the \texttt{gml} (generalized linear model) function. 
% problem
The test problem is a contrived one dimensional problem where given a health statistic ($h$) determine whether a patient will survive or not $s\in\{0,1\}$.
The \texttt{gml} is distributed in core R and provides a number of functions besides the logistic function. By default, the method uses the Iteratively Re-weighted Least Squares (IWLS) method to fit.

% TODO make 2D problem and show the decision boundary + data points

\begin{lstlisting}[language=r,label=examplelogit,caption={Example of Logistic Regression in R}]
	# generate random health score values
	health=sort(rnorm(20, 0, 50))
	# <0 not likely to survive
	survive=c(0,0,0,0,0,0,1,0,1,0,1,0,1,0,1,1,1,1,1,1)
	# two column data
	mydata=as.data.frame(cbind(health,survive))
	# create fit
	model=glm(survive~health, family=binomial(logit), mydata)
	# display summary of the fit
	summary(model)
	# plot the points
	plot(health, survive, xlab="Health Statistic",ylab="P(survival)")
	# draw the prediction curve on the plot
	curve(predict(model,data.frame(health=x),type="resp"),add=TRUE)
	# draw the prediction points (P(survival) for each health)
	points(health, fitted(model), pch=20)
\end{lstlisting}

% References: Deeper understanding
% The references element description includes a listing of both primary sources of information about the technique as well as useful introductory sources for novices to gain a deeper understanding of the theory and application of the technique. The description consists of hand-selected reference material including books, peer reviewed conference papers, journal articles, and potentially websites. A bullet-pointed structure is suggested.
\subsection{References}
% What are the primary sources for a technique?
% What are the suggested reference sources for learning more about a technique?

% primary sources
\subsubsection{Primary Sources}

What are some primary sources for this method?

% more info
\subsubsection{More Information}
%Komarek and Moore provide promote the use of the method in modern data mining, suggesting modifications to the fit procedure to decrease computational complexity \cite{Komarek2005}.

There are many excellent books dedicated to Logistic Regression, some examples include 
``Logistic Regression: A Primer'' by Pampel that provides a practical introduction to the method \cite{Pampel2000}, ``Applied logistic regression'' by Hosmer and Lemeshow that provides a wealth of references \cite{Hosmer2000}, and ``Logistic Regression: A Self-Learning Text'' by Kleinbaum, Klein, and Pryor that is also an excellent self-paced introductory text \cite{Kleinbaum2010}.


% END
