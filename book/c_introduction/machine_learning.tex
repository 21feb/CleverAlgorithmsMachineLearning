% The Clever Algorithms Project: http://www.CleverAlgorithms.com
% (c) Copyright 2013 Jason Brownlee. Some Rights Reserved. 
% This work is licensed under a Creative Commons Attribution-Noncommercial-Share Alike 2.5 Australia License.


% Machine Learning
\section{Machine Learning} 
\label{intro:machinelearning}
\index{Machine Learning}

% my def
Machine learning is concerned with methods that process empirical data to construct models that contain the salient or underlying probability distribution in the data. Such models may then be applied to address problems or make decisions regarding new data or data unseen by the system.
% this section
This section provides some standard definitions of machine learning and goes on to summarizes some of the over arching fields and related sub-fields.

% official definitions
\subsection{Definitions}
\label{subsec:definitions}
\index{Machine Learning!Definition}
This section visits standard definitions and descriptions of the field from some of the classical texts on statistical pattern recognition and machine learning. 

Fukunaga's classic text \emph{Introduction to Statistical Pattern Recognition} summarizes the field (\cite{Fukunaga1990}, page 2--3):

\begin{quotation}
... pattern recognition, or decision-making in a broader sense, may be considered as a problem of estimating density functions in a high-dimensional space and dividing the space into the regions of categories or classes. Because of this view, mathematical statistics forms the foundation of the subject.
\end{quotation} 

Hastie et~al.\ seminal text \emph{The Elements of Statistical Learning: Data Mining, Inference, and Prediction} describes a typical scenario (\cite{Hastie2009}, pages 1--2):

\begin{quotation}
... we have an outcome measurement, usually quantitative ... or categorical ..., that we wish to predict based on a set of features ... We have a training set of data, in which we observe the outcome and feature measurements for a set of objects ... Using this data we build a prediction model, or learner, which will enable us to predict the outcome for new unseen objects. A good learner is one that accurately predicts such an outcome.
\end{quotation} 

Duda et~al.\ classic text \emph{Pattern Classification} suggests (\cite{Duda2001}, page 16):

\begin{quotation}
In the broadest sense, any method that incorporates information from training samples in the design of a classifier employs learning. ... Learning refers to some form of algorithm for reducing the error on a set of training data.
\end{quotation}

Mitchell's classic text \emph{Machine Learning} suggests (\cite{Mitchell1997}, page xv):

\begin{quotation}
The field of machine learning is concerned with the question of how to construct computer programs that automatically improve with their experience.
\end{quotation}

Mitchell also provides a precise definition which is popular in the field (\cite{Mitchell1997}, page 2):

\begin{quotation}
A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measure by P, improves with experience E.
\end{quotation}

Mitchell suggests that the field of Machine Learning seeks to answer the question \cite{Mitchell2006}

\begin{quotation}
How can we build computer systems that automatically improve with experience, and what are the fundamental laws that govern all learning processes?
\end{quotation}

% Related fields
\subsection{Related Fields}
\label{subsec:related_fields}
\index{Machine Learning!Related Fields}
Machine Learning is a cross-disciplinary field that draws upon many related and overarching fields. This section describes some of those fields related to the study of Machine Learning in order to provide context.

% Artificial Intelligence
\subsubsection{Artificial Intelligence}
\index{Artificial Intelligence}
The field of Artificial Intelligence (AI) coalesced in the 1950s drawing on an understanding of the brain from neuroscience, the new mathematics of information theory, control theory referred to as cybernetics, and the dawn of the digital computer. AI is a cross-disciplinary field of research that is generally concerned with developing and investigating systems that operate or act intelligently. It is considered a discipline in the field of computer science given the strong focus on computation. The study of artificial intelligence is concerned with investigating mechanisms that underlie intelligence and intelligence behavior.

Russell and Norvig provide a perspective that defines artificial intelligence in four categories: 1) systems that think like humans, 2) systems that act like humans, 3) systems that think rationally, 4) systems that act rationally \cite{Russell2009}. In their definition, acting like a human suggests that a system can do some specific things humans can do, this includes fields such as the Turing test, natural language processing, automated reasoning, knowledge representation, machine learning, computer vision, and robotics. Thinking like a human suggests systems that model the cognitive information processing properties of humans, for example a general problem solver and systems that build internal models of their world. Thinking rationally suggests laws of rationalism and structured thought, such as syllogisms and formal logic. Finally, acting rationally suggests systems that do rational things such as expected utility maximization and rational agents. 

Machine Learning is concerned with developing systems that learn from experience, feature that may be considered a signature of intelligence. As such, machine learning may be considered a sub-field of artificial intelligence.

% Data Mining
\subsubsection{Data Mining}
\index{Data Mining}
Broadly, the field of Data Mining may be considered the practical application of statistical and machine learning methods to real-world problem domains. 
Witten and Frank provide a clear definition of the field (\cite{Witten2011}, page 5)

\begin{quotation}
Data mining is about solving problems by analyzing data already present in databases. ... Data mining is defined as the process of discovering patterns in data. The process must be automatic or (more usually) semiautomatic. The patterns discovered must be meaningful in that they lead to some advantage usually an economic advantage. The data is invariably present in substantial quantities.
\end{quotation}

The field traditionally uses the phrase `Knowledge Discovery in Databases' (KDD) to describe itself, focusing on the process of applying a suite of machine learning methods to solve a problem \cite{Frawley1992}. An early definition of this process proposed the following elements: Selection, Preprocessing, Transformation, Data Mining, Interpretation and Evaluation, where Data Mining is a single step in the procedure \cite{Fayyad1996a}.
% relation
This suggests Machine Learning methods as the tools that may be used in a KDD process and/or during Data Mining.

% Other
\subsubsection{Fundamentals}
This section describes those fundamental areas from which Machine Learning is rooted. 

\begin{description}
\index{Statistics}
	\item[Statistics]: The field of statistics is a branch of mathematics concerned the collection, organization, and interpretation of quantitative data. A statistical understanding of data provides a basis for machine learning methods that generalize from quantitative data, commonly characterizing the probabilistic features that underlie the observations.
	
\index{Computational Learning Theory}
	\item[Computational Learning Theory]: The field of Computational Learning Theory broadly involves the analysis of machine learning systems. The field provides the theoretical basis for types of learning and their limitations. Machine Learning methods can be developed to investigate a theoretical finding, or be made more efficient through theoretical discoveries. For more information, refer to Kearns and Vazirani \cite{Kearns1994}.
	
\index{Probability Theory}
	\item[Probability Theory]: The field of probability theory is a branch of mathematics concerned with the likelihood of random events and characterizing the distribution of occurrences. The findings and methods from probability theory provides a basis to the field of statistics. 
	
\index{Decision Theory}
	\item[Decision Theory]: The field of decision theory is concerned with rational and optimal decision making in the presence of uncertainty. The field is also closely related to game theory and probability theory. The findings from decision theory relate to the application of models in machine learning for the decisions made in discrimination and related tasks.
	
\index{Information Theory}
	\item[Information Theory]: The field of information theory from applied mathematics and computer science is concerned with the quantification of information in data. The field is based on probability theory and statistics, and focuses on the amount or change in information entropy which is the measure of information content associated with a message. Information theory is important in machine learning in compression and generalization that occurs in the preparation of a model from data samples. For more information refer to MacKay \cite{MacKay2003}.
\end{description}

The application of statistical and machine learning methods to specific domains are typically referred to as a standalone field, such as machine vision, speech recognition, machine translation, and information filtering.

%
% Taxonomies
%
\subsection{Taxonomies}
\label{sec:taxonomies}
\index{Machine Learning!Taxonomy}
Machine Learning is a large and complex multidisciplinary field. As such there are many perspectives or ways of breaking up the methods and algorithms it contains. This section considers a number of common taxonomies of Machine Learning methods.

% taxonomy by learning
We first consider a partitioning of the field by the type of learning performed by an algorithm used to prepare a model. Learning is performed from examples provided in the form of observations or samples from the domain they may be available or may have to be collected by a software agent. This data is referred to as the `training set'. 

The type of learning performed by an approach can be defined in terms of the feedback provided by the environment based on the decisions or actions taken by a model prepared from collected data.

\begin{description}
	\index{Unsupervised Learning}
	\item[Unsupervised Learning]: No feedback is provided from the environment. Methods are left to deduce structure and patterns. The most common models used in unsupervised learning include clustering algorithms that suggest natural groupings within the data.
	
	\index{Supervised Learning}
	\item[Supervised Learning]: Input data is associated with an output value or values, a relationship which can be learned and frequently assessed. This assessment may result in a performance or error measure that is used to further refine the model. A common example of problems for supervised learning include regression and classification where an ordinal or categorical output is associated with a collection of input data attributes. A model is prepared with a training dataset, then assessed with the same or a different test dataset, the results of which are fed back to the model for correction.
	
	\index{Semi-supervised Learning}
	\item[Semi-supervised Learning]: Input data may be associated with an output value or values, although only some labeled examples are provided, and/or examples may be mislabeled. This provides an intermediate that must exploit the capabilities of unsupervised learning where natural clusters are sought in the data, and supervised learning where known relationships are demonstrated between input and output data attributes. For more information see Zhu's literature survey \cite{Zhu2008} or book \cite{Zhu2009}, or the edited volume by Chapelle et~al.\ \cite{Chapelle2010}.
	
	\index{Reinforcement Learning}
	\item[Reinforcement Learning]: A model or agent learns in an environment through (likely sporadic and infrequent) reinforcements, such as rewards and/or punishments. A popular analogy is that the environment provides a critic (rather than a teacher) which makes suggestions of correctness or incorrectness without indication of why or what the correct answer might be. For more information, refer to Sutton and Bardo \cite{Sutton1998}.
\end{description}

An important distinction between machine learning methods is the relationship between the data and the nature of the model prepared from the data.

\begin{description}
	\index{Inductive Learning}
	\item[Inductive Learning]: The most common form of learning where specific examples in the form of observations from the domain are used as the basis for making generalizations to solve problems, such as natural groups or class discrimination boundaries. Generalization is based on statistics applied to the empirical observations and typically requires a large number of examples that are representative of the underlying structure (mass or density functions) in the data.
	
	\index{Analytical Learning}
	\item[Analytical Learning]: A form of learning where prior knowledge and deductive reasoning is used in conjunction with available data. Prior knowledge is used as an explanation for the features in training data, allowing generalization through logical rather than statistical reasoning. An example of analytical learning is Explanation-based Learning used in domains such as scheduling.
	
\end{description}

The process of model construction and generalization depends on the availability of data. Observations from the domain may be collected and used to prepare a model or a model may be updated as observations become available. The following summarizes the relationship between model learning and data availability.

\begin{description}
	\index{Online Learning}
	\item[Online Learning]: A system makes predictions on an instance-by-instance basis, where the actual outcome or result for the instance is provided directly or soon after the prediction is made. Once the actual outcome is known, the system can make any adjustments necessary to improve its predictive ability. The ongoing learning of an online system provides a capability to adapt to changes in data over extended periods of time.
	
	\index{Offline Learning} 
	\item[Offline Learning]: A sample of observations are collected beforehand from which the system may process for as long as needed. This sample or training dataset may be evaluated in order to derive holistic generalizations. A system maybe trained on the whole dataset or on selected sub-samples of the dataset in batch, giving the alternative name of batch learning. After the training phase has occurred, the approximation prepared by the system typically does not change for the life of the system.

\end{description}



