% The Clever Algorithms Project: http://www.CleverAlgorithms.com
% (c) Copyright 2010 Jason Brownlee. Some Rights Reserved. 
% This work is licensed under a Creative Commons Attribution-Noncommercial-Share Alike 2.5 Australia License.

% This is a chapter

\renewcommand{\bibsection}{\subsection{\bibname}}
\begin{bibunit}

\chapter{Regression}
\label{ch:regression}
\index{Regression}

\section{Overview}
This chapter describes Regression methods that common in the field of Machine Learning.

% Types of Regression Algorithms
\subsection{Taxonomy}
Regression is concerned with modeling the relationships between variables. In Machine Learning such methods are commonly used for predicting real and categorical variables. There are many frameworks used to understand regression models, this section summarizes some of them to provide a context for the regression methods described in this chapter.

\textbf{Linear Regression}: These are models where the relationship between dependent and independent variables is modeled using a linear function (first-degree polynomial) also known as Linear Regression. We find the set of coefficients that minimize the empirical loss, most commonly the squared error over all observations (referred to as $L_2$) assuming normally distributed noise. 

Extensions to Linear Regression are named after the feature they provide, for example \textbf{Multivariate Linear Regression} (also known as Multiple Linear Regression) is an extension from one independent variable (Univariate Linear Regression) to multiple independent variables.

Methods for estimating the coefficients...

% Non-Linear Regression ?????

% Examples are named after the methods for finding the coefficients, such as Ordinary Least Squares (OLR).

% , Generalized Least Squares (GLS), Iteratively Reweighted Least Squares (IRLS), Ridge Regression (RR), and Least-Angle Regression (LAR).

\textbf{Generalized Linear Model}: (GLM) This is a framework that generalizes Linear Regression and considers models as composed of 1) conditional probability for the response variable assumed to be in the exponential family 2) a linear predictor and 3) a smooth and invertible link function. GLMs models are most commonly fit by the method of maximum likelihood. The framework unified Linear Regression (normal distribution), Logistic Regression (binomial distribution), and Poisson Regression (poisson distribution). The Generalized Linear Model framework was proposed by Nelder and Wedderburn \cite{Nelder1972}. McCullagh and Nelder provide an in depth presentation in their seminal text \cite{McCullagh1989}.


% Nomenclature
\subsection{Nomenclature}

bias = intercept (beta 0)
regression line
dependent variable (Y)
independent variable (X)
coefficients (beta)
best fit
residual



% references
\subsection{Further Reading}



\putbib
\end{bibunit}

\newpage\begin{bibunit}\input{a_regression/ordinary_least_squares_regression}\putbib\end{bibunit}
\newpage\begin{bibunit}\input{a_regression/logistic_regression}\putbib\end{bibunit}
\newpage\begin{bibunit}\input{a_regression/stepwise_linear_regression}\putbib\end{bibunit}
\newpage\begin{bibunit}\input{a_regression/multivariate_adaptive_regression_splines}\putbib\end{bibunit}
\newpage\begin{bibunit}\input{a_regression/locally_weighted_regression}\putbib\end{bibunit}

