% Clever Algorithms: A Gentle Introduction to Machine Learning

% The Clever Algorithms Project: http://www.CleverAlgorithms.com
% (c) Copyright 2011 Jason Brownlee. Some Rights Reserved. 
% This work is licensed under a Creative Commons Attribution-Noncommercial-Share Alike 2.5 Australia License.

\documentclass[a4paper, 11pt]{article}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{url}
\usepackage[pdftex,breaklinks=true,colorlinks=true,urlcolor=blue,linkcolor=blue,citecolor=blue,]{hyperref}
\usepackage{geometry}
\geometry{verbose,a4paper,tmargin=25mm,bmargin=25mm,lmargin=25mm,rmargin=25mm}

% Dear template user: fill these in
\newcommand{\myreporttitle}{Clever Algorithms}
\newcommand{\myreportsubtitle}{A Gentle Introduction to Machine Learning}
\newcommand{\myreportauthor}{Jason Brownlee}
\newcommand{\myreportemail}{jasonb@CleverAlgorithms.com}
\newcommand{\myreportwebsite}{http://www.CleverAlgorithms.com}
\newcommand{\myreportproject}{The Clever Algorithms Project\\\url{\myreportwebsite}}
\newcommand{\myreportdate}{20110211}
\newcommand{\myreportfulldate}{\today}
\newcommand{\myreportversion}{1}
\newcommand{\myreportlicense}{\copyright\ Copyright 2011 Jason Brownlee. Some Rights Reserved. This work is licensed under a Creative Commons Attribution-Noncommercial-Share Alike 2.5 Australia License.}

% leave this alone, it's templated baby!
\title{{\myreporttitle}: {\myreportsubtitle}\footnote{\myreportlicense}}
\author{\myreportauthor\\{\myreportemail}\\\small\myreportproject}
\date{\myreportfulldate\\{\small{Technical Report: CA-TR-{\myreportdate}-\myreportversion}}}
\begin{document}
\maketitle

% write a summary sentence for each major section
\section*{Abstract} 
% project
The Clever Algorithms: Machine Learning project intends to describe a large number of methods from the field of Machine Learning in a complete, consistent, and centralized way, such that the descriptions are usable, accessible, and understandable.
% this report
This report provides a gentle introduction into the field of Machine Learning, providing a summary of standard taxonomies of methods, and highlighting important sub-disciplines. 

\begin{description}
	\item[Keywords:] {\small\texttt{Clever Algorithms, Machine Learning, Introduction}}
\end{description} 

% summarise the document breakdown with cross references
\section{Introduction}
\label{sec:introduction}
% project
The Clever Algorithms: Machine Learning project intends to describe a large number of methods from the field of Machine Learning in a complete, consistent, and centralized way, such that the descriptions are usable, accessible, and understandable \cite{Brownlee2011a}.
% this report
This report provides a brief summary of the field of Machine Learning by introducing common definitions and taxonomies.

% specific sections
Section~\ref{sec:machine_learning} defines the field of machine learning by collecting common and standard definitions from seminal texts in the field. The section goes on to clarify the relationship of machine learning to artificial intelligence and data mining as well as other theoretical sub-fields
Section~\ref{sec:taxonomies} summarizes the field using firstly from the perspective of learning and the different forms of learning methods in the field employ, and secondly from the perspective of the types of problems machine learning methods are typically applied.

%
% Machine Learning
%
\section{Machine Learning}
\label{sec:machine_learning}
% my def
Machine learning is concerned with methods that process empirical data to construct models that contain the salient or underlying probability distribution in the data. Such models may then be applied to address problems or make decisions regarding new data or data unseen by the system.
% this section
This section provides some standard definitions of machine learning (Section~\ref{subsec:definitions}) and goes on to summarizes some of the over arching and related sub-fields (Section~\ref{subsec:related_fields}).

% official definitions
\subsection{Definitions}
\label{subsec:definitions}
This section visits standard definitions and descriptions of the field from some of the classical texts on statistical pattern recognition and machine learning. 

Fukunaga's classic text \emph{Introduction to Statistical Pattern Recognition} summarizes the field (page 2--3, \cite{Fukunaga1990}):

\begin{quotation}
... pattern recognition, or decision-making in a broader sense, may be considered as a problem of estimating density functions in a high-dimensional space and dividing the space into the regions of categories or classes. Because of this view, mathematical statistics forms the foundation of the subject.
\end{quotation} 

Hastie et~al.\ seminal text \emph{The Elements of Statistical Learning: Data Mining, Inference, and Prediction} describes a typical scenario (pages 1--2, \cite{Hastie2009}):

\begin{quotation}
... we have an outcome measurement, usually quantitative ... or categorical ..., that we wish to predict based on a set of features ... We have a training set of data, in which we observe the outcome and feature measurements for a set of objects ... Using this data we build a prediction model, or learner, which will enable us to predict the outcome for new unseen objects. A good learner is one that accurately predicts such an outcome.
\end{quotation} 

Duda et~al.\ classic text \emph{Pattern Classification} suggests (page 16, \cite{Duda2001}):

\begin{quotation}
In the broadest sense, any method that incorporates information from training samples in the design of a classifier employs learning. ... Learning refers to some form of algorithm for reducing the error on a set of training data.
\end{quotation}

Mitchell's classic text \emph{Machine Learning} suggests (page xv, \cite{Mitchell1997}):

\begin{quotation}
The field of machine learning is concerned with the question of how to construct computer programs that automatically improve with their experience.
\end{quotation}

Mitchell provides a precise definition which will be used in this project (page 2, \cite{Mitchell1997}):

\begin{quotation}
A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measure by P, improves with experience E.
\end{quotation}

Mitchell suggests that the field of Machine Learning seeks to answer the question (\cite{Mitchell2006})

\begin{quotation}
How can we build computer systems that automatically improve with experience, and what are the fundamental laws that govern all learning processes?
\end{quotation}

Some additional excellent resources include Bishop's classical Neural Network text \emph{Neural Networks for Pattern Recognition} \cite{Bishop1995}, and his Machine Learning text \emph{Pattern Recognition and Machine Learning} \cite{Bishop2006}.

% Related fields
\subsection{Related Fields}
\label{subsec:related_fields}
Machine Learning is a cross-disciplinary field that draws upon many related and overarching fields. This section describes some of those fields related to the study of Machine Learning in order to provide context.

% Artificial Intelligence
\subsubsection{Artificial Intelligence}
The field of Artificial Intelligence (AI) coalesced in the 1950s drawing on an understanding of the brain from neuroscience, the new mathematics of information theory, control theory referred to as cybernetics, and the dawn of the digital computer. AI is a cross-disciplinary field of research that is generally concerned with developing and investigating systems that operate or act intelligently. It is considered a discipline in the field of computer science given the strong focus on computation. The study of artificial intelligence is concerned with investigating mechanisms that underlie intelligence and intelligence behavior.

Russell and Norvig provide a perspective that defines artificial intelligence in four categories: 1) systems that think like humans, 2) systems that act like humans, 3) systems that think rationally, 4) systems that act rationally \cite{Russell2009}. In their definition, acting like a human suggests that a system can do some specific things humans can do, this includes fields such as the Turing test, natural language processing, automated reasoning, knowledge representation, machine learning, computer vision, and robotics. Thinking like a human suggests systems that model the cognitive information processing properties of humans, for example a general problem solver and systems that build internal models of their world. Thinking rationally suggests laws of rationalism and structured thought, such as syllogisms and formal logic. Finally, acting rationally suggests systems that do rational things such as expected utility maximization and rational agents. 

Machine Learning is concerned with developing systems that learn from experience -- feature that may be considered a signature of intelligence. As such, machine learning may be considered a sub-field of artificial intelligence.

% Data Mining
\subsubsection{Data Mining}
Broadly, the field of Data Mining may be considered the practical application of statistical and machine learning methods to real-world problem domains. 
Witten and Frank provide a clear definition of the field (page 5, \cite{Witten2000})

\begin{quotation}
Data mining is about solving problems by analyzing data already present in databases. ... Data mining is defined as the process of discovering patterns in data. The process must be automatic or (more usually) semiautomatic. the patterns discovered must be meaningful in that they lead to some advantage usually an economic advantage. The data is invariably present in substantial quantities.
\end{quotation}

The field traditionally uses the phrase `Knowledge Discovery in Databases' (KDD) to describe itself, focusing on the process of applying a suite of machine learning methods to solve a problem \cite{Frawley1992}. An early definition of this process proposed the following elements: Selection, Preprocessing, Transformation, Data Mining, Interpretation and Evaluation, where Data Mining is a single step in the procedure \cite{Fayyad1996a}.
% relation
This suggests Machine Learning methods as the tools that may be used in a KDD process and/or during Data Mining.

% Other
\subsubsection{Other}
This section describes those fields from which Machine Learning draws upon. 

\begin{description}
	\item[Statistics]: The field of statistics is a branch of mathematics concerned the collection, organization, and interpretation of quantitative data. A statistical understanding of data provides a basis for machine learning methods that generalize from quantitative data, commonly characterizing the probabilistic features that underlie the observations.
	
	\item[Computational Learning Theory]: The field of Computational Learning Theory broadly involves the analysis of machine learning systems. The field provides the theoretical basis for types of learning and their limitations. Machine Learning methods can be developed to investigate a theoretical finding, or be made more efficient through theoretical discoveries. For more information, refer to Kearns and Vazirani's \emph{An introduction to computational learning theory} \cite{Kearns1994}.
	
	\item[Probability Theory]: The field of probability theory is a branch of mathematics concerned with the likelihood of random events and characterizing the distribution of occurrences. The findings and methods from probability theory provides a basis to the field of statistics. 
	
	\item[Decision Theory]: The field of decision theory is concerned with rational and optimal decision making in the face of uncertainty. The field is also closely related to game theory and probability theory. The findings from decision theory relate to the application of models in machine learning for the decisions made in discrimination and related tasks.
	
	\item[Information Theory]:	The field of information theory from applied mathematics and computer science is concerned with the quantification of information in data. The field is based on probability theory and statistics, and focuses on the amount or change in information entropy which is the measure of information content associated with a message. Information theory is important in machine learning in compression and generalization that occurs in the preparation of a model from data samples. For more information refer to MacKay's \emph{Information theory, inference, and learning algorithms} \cite{MacKay2003}.
\end{description}

The application of statistical and machine learning methods to specific domains are typically referred to as a standalone field, such as machine vision, speech recognition, machine translation, and information filtering.

%
% Taxonomies
%
\section{Taxonomies}
\label{sec:taxonomies}
Machine Learning is a large and complex multidisciplinary field. As such there are many perspectives or ways of breaking up the methods and algorithms it contains. This section considers a number of common perspectives or taxonomies of methods in the field of Machine Learning.

% taxonomy by learning
\subsection{Learning}
\label{subsec:learning}
This section considers a partitioning of the field by the type of learning performed by an algorithm used to prepare a model. Learning is performed from examples provided in the form of observations or samples from the domain that may available or may have to be collected by a software agent, data referred to as the `training set'. The type of learning performed by an approach can be defined in terms of the feedback provided by the environment based on the decisions or actions taken by a model prepared from collected data.

\begin{description}
	\item[Unsupervised Learning]: No feedback is provided from the environment. Methods are left to deduce structure and patterns. The most common models used in unsupervised learning include clustering algorithms that suggest natural groupings within the data.
	
	\item[Supervised Learning]: Input data is associated with an output value or values, a relationship which can be learned and frequently assessed. This assessment may result in a performance or error measure that may be used to further refine the model. A common example of problems for supervised learning include classification where an ordinal or categorical output is associated with a collection of input data attributes. A model is prepared with a training dataset, then assessed with the same or a different test dataset, the results of which are fed back to the model for correction.
	
	\item[Semi-supervised Learning]: Input data may be associated with an output value or values, although only some labeled examples are provided, and/or examples may be mislabeled. This provides an intermediate that must exploit the capabilities of unsupervised learning where natural clusters are sought in the data, and supervised learning where known relationships are demonstrated between input and output data attributes. 
	
	\item[Reinforcement Learning]: A model or agent learns in an environment through (likely sporadic and infrequent) reinforcements, such as rewards and/or punishments. A popular analogy is that the environment provides a critic (rather than a teacher) which makes suggestions of correctness or incorrectness without indication of why or what the correct answer might be.
\end{description}

An important distinction between machine learning methods is the relationship between the data and the nature of the model prepared from the data.

\begin{description}
	\item[Inductive Learning]: The most common form of learning where specific examples in the form of observations from the domain are used as the basis for making generalizations to solve problems, such as natural groups or class discrimination boundaries. Generalization is based on statistics applied to the empirical observations and typically requires a large number of examples that are representative of the underlying structure (mass or density functions) in the data.
	
	\item[Analytical Learning]: A form of learning where prior knowledge and deductive reasoning is used in conjunction with available data. Prior knowledge is used as an explanation for the features in training data, allowing generalization through logical rather than statistical reasoning. An example of analytical learning is Explanation-based Learning used in domains such as scheduling.
	
\end{description}

The process of model construction and generalization depends on the availability of data. Observations from the domain may be collected and used to prepare a model or a model may be updated as observations become available. The following summarizes the relationship between model learning and data availability.

\begin{description}
	\item[Online Learning}: A system makes predictions on an instance-by-instance basis, where the actual outcome or result for the instance is provided directly or soon after the prediction is made. Once the actual outcome is known, the system can make any adjustments necessary to improve its predictive ability. The ongoing learning of an online system provides a capability to adapt to changes in data over extended periods of time.
	
	\item[Offline Learning]: A sample of observations are collected beforehand from which the system may process for as long as needed. This sample or training dataset may be evaluated in order to derive holistic generalizations. A system maybe trained on the whole dataset or on selected sub-samples of the dataset in batch, giving the alternative name of batch learning. After the training phase has occurred, the approximation prepared by the system typically does not change for the life of the system.

\end{description}


% taxonomy by problem
\subsection{Problems}
\label{subsec:problems}
There are many subtly different classes of problem's that may be addressed via machine learning methods, all generally stemming from the abstract problem of Function Approximation. Function approximation is the problem of finding a function ($f$) that approximates a target function ($g$), where typically the approximated function is selected based on a sample of observations ($x$, also referred to as the training set) taken from the unknown target function.
In Machine Learning, the function approximation formalism is used to describe general problem types commonly referred to as pattern recognition, such as classification, clustering, and curve fitting (called a decision or discrimination function). Such general problem types are described in terms of approximating an unknown Probability Density Function, which underlies the relationships in the problem space, and is represented in the sample data. This perspective of such problems is commonly referred to as statistical machine learning and/or density estimation.

% general process
The general process focuses on 1) the collection and preparation of the observations from the target function, 2) the selection and/or preparation of a model of the target function, and 3) the application and ongoing refinement of the prepared model. 
% optimization
The field of Function Optimization is related to function approximation, as many-sub-problems of function approximation may be defined as optimization problems. Many of the technique paradigms used for function approximation are differentiated based on the representation and the optimization process used to minimize error or maximize effectiveness on a given approximation problem. 
% problems
The difficulty of function approximation problems center around 1) the nature of the unknown relationships between attributes and features, 2) the number (dimensionality) of attributes and features, and 3) general concerns of noise in such relationships and the dynamic availability of samples from the target function.
% other problems
Additional difficulties include the incorporation of prior knowledge (such as imbalance in samples, incomplete information and the variable reliability of data), and problems of invariant features (such as transformation, translation, rotation, scaling, and skewing of features).

The following describes some of the general sub-problems of function approximation addressed via Machine Learning methods:

\begin{description}
	\item[Feature Selection]: A feature is considered an aggregation of one-or-more attributes, where only those features that have meaning in the context of the target function are necessary to the modeling function. Feature selection methods may be used to reduce the dimensionality of a dataset, before addressing a follow-up problem such as classification. It is common to assess the information content of attributes in feature selection methods, or more crudely to determine the effect on models with and without specific attributes to determine their utility.
	
	\item[Classification]: Observations are inherently organized into labeled groups (classes) and a supervised process models an underlying discrimination function to classify unobserved samples. A system must deduce the boundaries between classes and be able to discriminate based on the class boundaries. Classification problems are addressed through a supervised learning method given labeled data from the domain is available to teach the model the class boundaries. 
	
	\item[Clustering]: Observations may be organized into natural groups based on underlying structure or features in the data. The groups are unlabeled requiring a process to model an underlying discrimination function without corrective feedback. As such, unsupervised methods are commonly used for clustering problems. Resulting data clusters may be labeled after the fact and used as the basis for follow-on classification problems.
	
	\item[Regression]: A model is prepared that provides a `best-fit' for a set of observations that may be used for interpolation over known observations and extrapolation for observations outside what has been modeled. The best-fit may be two-dimensional (line-fitting) or higher-dimensionality (surface fitting). It is common for regression problems to have a time axis.
	
	\item[Association]: Rules may be deduced between attributes in the data and may discover interesting and useful statistical patterns. Such rules may or may not be related to the predicted attributes, such as the class in a classification problem, and may useful for identifying "important" attributes such as in feature selection.
		
\end{description}


% going forward
\section{Outcomes}
\label{sec:conclusions}
This report has provided a gentle introduction to the field of Machine Learning. A core open question is that of which algorithms to describe in the project, and the taxonomy that should be used to organize them. A follow-up report is proposed to address this question that will:

\begin{enumerate}
	\item Review taxonomies used in popular books as well as standard software libraries to organize and present machine learning. This comparative analysis will provide the basis for an informed decision on an appropriate taxonomy by which to organize the algorithms in the project.
	\item Collate a large list of so-called machine learning algorithm names, organized by a chosen taxonomy and evaluate the commonality and popularity of each. This will provide the basis for making informed decisions as to appropriate algorithms or method types to describe in the project.
\end{enumerate}

There are many interesting areas of the field that could be covered in introductory or advanced topics. The following provides a listing of possible topics that may require a deeper investigation in or as a part of a follow-up technical report in this project:

\begin{itemize}
	\item Data Mining - an overview of the field of data mining as the application of machine learning (and other) methods, with a focus on the standardized methodologies that may be adopted for solving problems and building systems.
	\item Regularization - an overview of the methods that can be used to avoid over-fitting a model to data, with a focus on the popular approaches such as cross-validation.
	\item Visualization - an overview of common visualization methods for data sets, models, and discrimination boundaries. This would most likely involve examples using a common visualization toolkit such as R or GnuPlot.
	\item Evaluation - an overview of problem and technique performance and evaluation measures and how they may be interpreted. 
\end{itemize}


% 
% Contribute
% 
\section{Contribute}
\label{sec:contribute}
% advanced 
Are you an expert in this field and know some facts that could improve the algorithm description for all?
% incentive
Do you want to get that warm feeling from contributing to an open source project? 
Do you want to see your name as an acknowledgment in print?

%  ideal
Two pillars of this effort are 1) that the best domain experts are people outside of the project, and 2) that this work is subjected to continuous improvement. 
% advice
Please help to make this work less wrong by emailing the author `\myreportauthor' at \url{\myreportemail} or visit the project website at \url{\myreportwebsite}.

% bibliography
\bibliographystyle{plain}
\bibliography{../bibtex}

\end{document}
% EOF
