% Clever Algorithms: Machine Learning Algorithm Selection

% The Clever Algorithms Project: http://www.CleverAlgorithms.com
% (c) Copyright 2011 Jason Brownlee. Some Rights Reserved. 
% This work is licensed under a Creative Commons Attribution-Noncommercial-Share Alike 2.5 Australia License.

\documentclass[a4paper, 11pt]{article}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{url}
\usepackage[pdftex,breaklinks=true,colorlinks=true,urlcolor=blue,linkcolor=blue,citecolor=blue,]{hyperref}
\usepackage{geometry}
\geometry{verbose,a4paper,tmargin=25mm,bmargin=25mm,lmargin=25mm,rmargin=25mm}

% Dear template user: fill these in
\newcommand{\myreporttitle}{Clever Algorithms}
\newcommand{\myreportsubtitle}{Machine Learning Algorithm Selection}
\newcommand{\myreportauthor}{Jason Brownlee}
\newcommand{\myreportemail}{jasonb@CleverAlgorithms.com}
\newcommand{\myreportwebsite}{http://www.CleverAlgorithms.com}
\newcommand{\myreportproject}{The Clever Algorithms Project\\\url{\myreportwebsite}}
\newcommand{\myreportdate}{20110213}
\newcommand{\myreportfulldate}{\today}
\newcommand{\myreportversion}{1}
\newcommand{\myreportlicense}{\copyright\ Copyright 2011 Jason Brownlee. Some Rights Reserved. This work is licensed under a Creative Commons Attribution-Noncommercial-Share Alike 2.5 Australia License.}

% leave this alone, it's templated baby!
\title{{\myreporttitle}: {\myreportsubtitle}\footnote{\myreportlicense}}
\author{\myreportauthor\\{\myreportemail}\\\small\myreportproject}
\date{\myreportfulldate\\{\small{Technical Report: CA-TR-{\myreportdate}-\myreportversion}}}
\begin{document}
\maketitle

% write a summary sentence for each major section
\section*{Abstract} 
% project
The Clever Algorithms: Machine Learning project intends to describe a large number of methods from the field of Machine Learning in a complete, consistent, and centralized way, such that the descriptions are usable, accessible, and understandable.
% this report
This report provides...


\begin{description}
	\item[Keywords:] {\small\texttt{Clever Algorithms, Taxonomy, Algorithm Selection, Data Driven}}
\end{description} 

%
% Introduction
%
\section{Introduction}
\label{sec:introduction}
% project
The Clever Algorithms: Machine Learning project intends to describe a large number of methods from the field of Machine Learning in a complete, consistent, and centralized way, such that the descriptions are usable, accessible, and understandable \cite{Brownlee2011a}.
% the old method
A previous study...
% this report
This report provides...


%
% Algorithm Organization
%
\section{Algorithm Organization}
\label{sec:organization}
This section reviews the ways in which machine learning algorithms are organized in popular books and software libraries. This review is expected to provide the basis for an organization or taxonomy to be adopted in the clever algorithms project.

...books are about topics, libraries are about information processing similarity. the library analogy is a closer fit for the book.


% Books
\subsection{Books}
Books...

% The Elements of Statistical Learning: Data Mining, Inference, and Prediction
\subsection{The Elements of Statistical Learning: Data Mining, Inference, and Prediction}
Table~\ref{tab:teofl} summarizes the distribution of machine algorithms across chapters in \emph{The Elements of Statistical Learning: Data Mining, Inference, and Prediction} by Hastie et~al.\ \cite{Hastie2009}). This summary is not exhaustive, rather was deduced from the table of contents. 

\begin{table}[ht]
	\centering\footnotesize
		\begin{tabularx}{\textwidth}{>{\hsize=.5\hsize}XX}
		\toprule
		\textbf{Chapter} & \textbf{Algorithm Names} \\ 
		\toprule
		Overview of Supervised Learning & Least Squares, Nearest Neighbor  \\
		\midrule
		Linear Methods for Regression & Linear Regression, Ridge Regression, Lasso, Least Angle Regression, Principal Components Regression, Partial Lest Squares \\
		\midrule
		Linear Methods for Classification & Linear Discriminant Analysis, Logistic Regression, Perceptron \\
		\midrule
		Bias Expansion and Regularization & Piecewise Polynomials, Splines, Smoothing splines, Nonparametric Logistic Regression, RKHS, Wavelet \\
		\midrule
		Kernel Smoothing Methods & Local Linear Regression, Local Polynominal Regression, Naive Bayes Classifier \\
		\midrule
		Model Assessment and Selection & Cross-Validation, Bootstrap Methods \\
		\midrule
		Model Inference and Averaging & Bootstrap Methods, EM Algorithm, MCMC sampling of the Posterior \\
		\midrule		
		Additive Models, Trees, and Related Methods & Regression Trees, Classification Trees, PRIM, MARS \\
		\midrule		
		Noosting and Additive Trees & Boosting, AdaBoost, Gradient Boosting,  \\
		\midrule
		Neural Networks & Projection Pursuit Regression, Multiple Layer Perceptron,  \\
		\midrule
		Support Vector Machines and Flexible Discriminants & Support Vector Classifier, Support Vector Machine, Linear Discriminant Analysis, Flexible Discriminant Analysis \\
		\midrule
		Prototype Methods and Nearest-Neighbors & k-Means, LVQ, Gaussian Mixtures, l-Nearest-Neighbor classifiers, Adaptive Nearest-Neighbor, \\
		\midrule
		Unsupervised Learning & Association Rules, Apriori Algorithm, K-means, Gaussian Mixtures, Vector Quantization, Self-Organizing Maps, Principle Components, Principle Curves, Spectral Clustering, Kernel Principle Components, Sparse Principle Components, Independent Component Analysis,  \\
		\midrule
		Random Forests & Random Forests \\
		\midrule
		Ensemble Learning & Boosting \\
		\midrule		
		Unidirected Graphical Models & Markov Graph, Hidden Markov Model, Restricted Boltzmann Machines \\
		\midrule
		High-Dimensional Problems & Regularized Discriminant Analysis \\
		\bottomrule
		\end{tabularx}	
	\caption{Summary of algorithm names by chapter in \empty{The Elements of Statistical Learning: Data Mining, Inference, and Prediction}.}
	\label{tab:teofl}
\end{table}

% Machine Learning
\subsection{Machine Learning}
Table~\ref{tab:mlbook} summarizes the distribution of machine algorithms across chapters in \emph{Machine Learning} by Mitchell \cite{Mitchell1997}). This summary is not exhaustive, rather was deduced from the table of contents. 

\begin{table}[ht]
	\centering\footnotesize
		\begin{tabularx}{\textwidth}{>{\hsize=.5\hsize}XX}
		\toprule
		\textbf{Chapter} & \textbf{Algorithm Names} \\ 
		\toprule
		Concept Learning and the General-to-Specific Ordering & Version Spaces, Candidate-Elimination algorithm, \\
		\midrule
		Decision Tree Learning & Decision Tree\\
		\midrule		
		Artificial Neural Networks & Perceptron, Backpropagation algorithm, \\
		\midrule		
		Evaluating Hypotheses & N/A \\
		\midrule		
		Bayesian Learning & Maximum Likelihood, Least-Squares, Bayes Classifier, Naive Bayes Classifier, Bayesian Belief Network, EM Algorithm, k-Means \\
		\midrule				
		Computational Learning Theory & PAC Learning, Vapnik-Chervonenkis Dimension \\
		\midrule		
		Instance-Based Learning & k-Nearest Neighbor, Locally Weighted Regression, Locally Weighted Linear Regression, Radial Basis Function, Case-Based Reasoning \\
		\midrule		
		Genetic Algorithms & Genetic Algorithm, Genetic Programming \\
		\midrule		
		Learning Sets of Rules & First-Order Rules \\
		\midrule		
		Analytical Learning & N/A \\
		\midrule		
		Combining Inductive and Analytical Learning & KBANN Algorithm , TangentProp Algorithm, EBNN Algorithm, FOCL Algorithm\\
		\midrule		
		Reinforcement Learning & Q Learning, Temporal Difference Learning\\
		\bottomrule
		\end{tabularx}	
	\caption{Summary of algorithm names by chapter in \empty{Machine Learning}.}
	\label{tab:mlbook}
\end{table}


% Software
\subsection{Software}
This section reviews the algorithms provided by popular open source machine learning software, and summarizes the groupings or taxonomies used to organize the provided algorithms.

\subsubsection{WEKA}
WEKA is a Machine Learning library and platform written in the Java programming language \cite{Hall2009, Witten2000}. WEKA is short for the Waikato Environment for Knowledge Analysis. Table~\ref{tab:weka} provides a summary of the grouping of algorithms provided in the WEKA machine learning workbench software library version 3.6.4. Specifically, the table provides the class names used in the software, most of which given an indication of the implemented technique.  

\begin{table}[ht]
	\centering\footnotesize
		\begin{tabularx}{\textwidth}{lX}
		\toprule
		\textbf{WEKA Group} & \textbf{WEKA Class Name} \\ 
		\toprule
		bayes & AODE, AODEsr, BayesianLogisticRegression, BayesNet, ComplementNaiveBayes, DMNBtext, HNB, NaiveBayes, NaiveBayesMultinominal, NaiveBayesMultinominalUpdateable, NaiveBayesSimple, NaiveBayesUpdateable, WAODE \\
		\midrule
		functions & GaussianProcesses, IsotonicRegression, LeastMedSq, LibLINEAR, LibSVM, LinearRegression, Logistic, MultiLayerPerceptron, PaceRegression, PLSClassifier, PLSCalssifier, RBFNetwork, SimpleLinearRegression, SimpleLogistic, SMO, SMOreg, SPegasos, VotedPerceptron, Winnow \\
		\midrule
		lazy & IB1, IBk, KStar, LBR, LWL \\
		\midrule
		meta & AdaBoostM1, AdditiveRegression, AttributeSelectionclassifier, Bagging, ClassificationViaClustering, ClassificationViaRegression, CostSensitiveClassifier, CVParameterSelection, Dagging, Decorate, END, FilteredClassifier, Grading, GridSearch, LogitBoost, MetaCost, MultiBoostAB, MultiClassClassifier, MultiScheme, OrdinalClassClassifier, RacedIncrementalLogitBoost, RandomCommittee, RandomSubSpace, RegressionByDiscretization, RotationForest, Stacking, StackingC, ThresholdSelector, Vote \\
		\midrule
		meta.nestedDichotomies & ClassBalancedND, DataNearBalancedND, ND \\
		\midrule
		mi & CitationKNN, MDD, MIBoost, MIDD, MIEMDD, MILR, MINND, MIOptimalBall, MISMO, MISVM, MIWraper, SimpleMI \\
		\midrule
		misc & HyperPipes, SerializedClassifier, VFI  \\
		\midrule
		rules & ConjunctiveRule, DecisionTable, DTNB, JRip, M5Rules, NNge, OpneR, PART, Prism, Ridor, ZeroR \\
		\midrule
		trees & ADTree, BFTreem DecisionStump, FT, Id3, J48, J48graph, LADTree, LMT, M5P, NBTree, RandomForrest, RandomTree, REPTree, SimpleCart, UserClassifier \\
		\midrule
		clusterers & CLOPE, Cobweb, DBScan, EM, FarthestFirst, FilteredClusterer, HierarchicalClusterer, MakeDensityBasedClusterer, OPTICS, sIB, SimpleKMeans, XMeans \\
		\midrule
		associate & Apriori, FilteredAssociator, FPGrowth, GeneralizedSequentialPatterns, PredictiveApriori, Tertius \\
		\bottomrule
		\end{tabularx}	
	\caption{Summary of algorithms provided in WEKA and their grouping.}
	\label{tab:weka}
\end{table}

\subsubsection{R-Project}
R is an an open source environment for statistical programming and visualization. A strength of the platform is the large number of third party libraries available. The Comprehensive R Archive Network (CRAN) provides access to these third party libraries, and one perspective on these libraries is specific tasks or roles, such as machine learning. Table~\ref{tab:r} provides a summary of the machine learning packages and algorithms provided on the `CRAN Task View: Machine Learning \& Statistical Learning' maintained by Torsten Hothorn and last updated on December 10th 2010\footnote{\url{http://cran.r-project.org/web/views/MachineLearning.html}}.  

\begin{table}[htp]
	\centering\footnotesize
		\begin{tabularx}{\textwidth}{>{\hsize=.3\hsize}XX}
		\toprule
		\textbf{R Group} & \textbf{R-Package or Algorithm Name} \\ 
		\toprule
		Neural Networks & nnet (single-hidden-layer neural network), RSNNS (Stuttgart Neural Network Simulator: Backpropagation, Counterpropagation, Quickprop, Backpercolation, RProp, Generalized radial basis functions, ART1, ART2, ARTMAP, Cascade Correlation, Recurrent Cascade Correlation, Dynamic LVQ, Backpropagation through time, Quickprop through time, Self-organizing maps, TDNN, Jordan networks, Elman networks, Associative Memory) \\
		\midrule
		Recursive Partitioning & rpart (Recursive partitioning and regression trees, CART-like trees), tree (Classification and Regression Trees),  party (recursive partitioning, conditional inference trees conditional inference trees, random forests, recursive partitioning based on parametric models), mvpart (Multivariate regression trees), knnTree (tree algorithm fitting nearest neighbors), LogicReg (Logic Regression) \\
		\midrule
		Random Forests & randomForest (forest of trees using random inputs), ipred (indirect classification and bagging for classification, regression and survival problems as well as resampling based estimators of prediction error), randomSurvivalForest (survival forests for right-censored and competing risks survival data), quantregForest (Quantile Regression Forests), LogicForest (logic regression trees), varSelRF (Variable selection from random forests using both backwards variable elimination), Boruta (feature selection algorithm based on a randomForest classifier) \\
		\midrule
		Regularized and Shrinkage Methods & lasso2 (L1 constrained estimation aka lasso), lars (Least Angle Regression, Lasso and Forward Stagewise), grplasso (GLM models with Group Lasso penalty), glmpath (L1 Regularization Path for Generalized Linear Models and Cox Proportional Hazards Model), elasticnet (Elastic-Net for Sparse Estimation and Sparse PCA), relaxo (Relaxed Lasso),  earth (Multivariate Adaptive Regression Spline Models), penalizedSVM (Feature Selection SVM using penalty functions), hda (Heteroscedastic Discriminant Analysis), rda (Shrunken Centroids Regularized Discriminant Analysis), sda (Shrinkage Discriminant Analysis and Feature Selection), SDDA (Stepwise Diagonal Discriminant Analysis) \\
		\midrule
		Boosting & gbm (extensions to Freund and Schapire's AdaBoost algorithm and Friedman's gradient boosting machine. Includes regression methods for least squares, absolute loss, quantile regression, logistic, Poisson, Cox proportional hazards partial likelihood, and AdaBoost exponential loss), GAMBoost (Generalized linear and additive models by likelihood based boosting), mboost (Functional gradient descent algorithm), CoxBoost (Cox models by likelihood based boosting for a single survival endpoint or competing risks) \\
		\midrule
		Support Vector Machines and Kernel Methods & e1071 (latent class analysis, short time Fourier transform, fuzzy clustering, support vector machines, shortest path computation, bagged clustering, naive Bayes classifier), kernlab (Support Vector Machines, Spectral Clustering, Kernel PCA and a QP solver), klaR (Classification and visualization), rdetools (Relevant Dimension Estimation in Feature Spaces) \\
		\midrule
		Bayesian Methods & BayesTree (Bayesian Additive Regression Trees), tgp (Bayesian treed Gaussian process models, Bayesian linear models, CART, treed linear models, stationary separable and isotropic Gaussian processes), BPHO (Bayesian Prediction with High-order Interactions), predbayescor (Classification rule based on Bayesian naive Bayes models with feature selection bias corrected)  \\
		\midrule
		Optimization using Genetic Algorithms & gafit (Genetic Algorithm for Curve Fitting), rgp (Genetic Programming), rgenoud (GENetic Optimization Using Derivatives) \\
		\midrule
		Association Rules & arules (Apriori and Eclat) \\
		\midrule
		Model selection and validation & e1071 (latent class analysis, short time Fourier transform, fuzzy clustering, support vector machines, shortest path computation, bagged clustering, naive Bayes classifier), ipred (indirect classification and bagging for classification, regression and survival problems as well as resampling based estimators of prediction error), svmpath (the SVM Path algorithm), ROCR (visualizing the performance of scoring classifiers), caret (classification and Regression Training) \\
		\bottomrule
		\end{tabularx}	
	\caption{Summary of algorithms provided in Machine Learning task-view in CRAN for R.}
	\label{tab:r}
\end{table}

%
% Algorithm Assessment
%
\section{Algorithm Assessment}
\label{sec:assessment}
This section assesses a listing of known machine learning algorithms to determine their commonality and popularity. It is expected that the results from this section will provide the basis for selecting the algorithms to be described in the clever algorithms project.

% Methodology
\subsection{Methodology}

% Results
\subsection{Results}

% Analysis
\subsection{Analysis}



%
% Selected Algorithms
%
\section{Selected Algorithms}
\label{sec:selected}
This section provides a preliminary description of the machine learning algorithms that will be described in the clever algorithms project. This list includes a summary of the chosen algorithm taxonomy that will be used to organize those algorithms that are described. 

% Adopted Taxonomy
\subsection{Taxonomy}
the taxonomy


% Adopted Taxonomy
\subsection{Algorithms}
the algorithms



%
% Conclusions
%
\section{Conclusions}
\label{sec:conclusions}
todo...




% 
% Contribute
% 
\section{Contribute}
\label{sec:contribute}
% advanced 
Are you an expert in this field and know some facts that could improve the algorithm description for all?
% incentive
Do you want to get that warm feeling from contributing to an open source project? 
Do you want to see your name as an acknowledgment in print?

%  ideal
Two pillars of this effort are 1) that the best domain experts are people outside of the project, and 2) that this work is subjected to continuous improvement. 
% advice
Please help to make this work less wrong by emailing the author `\myreportauthor' at \url{\myreportemail} or visit the project website at \url{\myreportwebsite}.

% bibliography
\bibliographystyle{plain}
\bibliography{../bibtex}

\end{document}
% EOF
