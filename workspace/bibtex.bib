% This file was created with JabRef 2.7.2.
% Encoding: UTF-8

@BOOK{Bishop2007,
  title = {Pattern Recognition and Machine Learning},
  publisher = {Springer},
  year = {2007},
  author = {Christopher M. Bishop},
  owner = {jasonb},
  timestamp = {2011.12.24}
}

@BOOK{Boyd2004,
  title = {Convex optimization},
  publisher = {Cambridge University Press},
  year = {2004},
  author = {Boyd, S.P. and Vandenberghe, L.},
  isbn = {9780521833783},
  lccn = {2003063284},
  url = {http://books.google.com.au/books?id=mYm0bLd3fcoC}
}

@BOOK{Braun2007,
  title = {A first course in statistical programming with R},
  publisher = {Cambridge University Press},
  year = {2007},
  author = {W. J. Braun and D. J. Murdoch},
  isbn = {9780521872652},
  lccn = {2008295814},
  url = {http://books.google.com.au/books?id=aodgVNrU\_8IC}
}

@MANUAL{Brehen2011,
  title = {{Package `grpreg'}: Regularization paths for regression models with
	grouped covariates},
  author = {Patrick Brehen},
  month = {July},
  year = {2011},
  owner = {brownlee},
  timestamp = {2011.12.13},
  url = {http://cran.r-project.org/web/packages/grpreg/grpreg.pdf}
}

@ARTICLE{Breiman2001,
  author = {Leo Breiman},
  title = {Random Forests},
  journal = {Machine Learning},
  year = {2001},
  volume = {45},
  pages = {5--32},
  number = {1},
  bibsource = {DBLP, http://dblp.uni-trier.de},
  ee = {http://dx.doi.org/10.1023/A:1010933404324}
}

@ARTICLE{Breiman1996,
  author = {Breiman, Leo},
  title = {Bagging predictors},
  journal = {Mach. Learn.},
  year = {1996},
  volume = {24},
  pages = {123--140},
  month = {August},
  acmid = {231989},
  address = {Hingham, MA, USA},
  doi = {10.1023/A:1018054314350},
  issn = {0885-6125},
  issue = {2},
  keywords = {aggregation, averaging, bootstrap, combining},
  numpages = {18},
  publisher = {Kluwer Academic Publishers},
  url = {http://dl.acm.org/citation.cfm?id=231986.231989}
}

@TECHREPORT{Breiman2003,
  author = {Leo Breiman and Adele Cutler},
  title = {Manual: Setting up, using, and understanding Random Forests v4.0},
  institution = {University of California, Berkeley},
  year = {2003},
  owner = {brownlee},
  timestamp = {2011.12.09}
}

@BOOK{Breiman1984,
  title = {Classification and regression trees},
  publisher = {Chapman and Hall},
  year = {1984},
  author = {Breiman, Leo and Friedman, J. H. and Olshen, R. A. and Stone, C.
	J.},
  owner = {brownlee},
  timestamp = {2011.11.23}
}

@BOOK{Brent1973,
  title = {Algorithms for Minimization without Derivatives},
  publisher = {Prentice--Hall},
  year = {1973},
  author = {R. Brent},
  owner = {jasonb},
  timestamp = {2011.12.26}
}

@ARTICLE{Broyden1970,
  author = {Broyden, C. G.},
  title = {{The Convergence of a Class of Double-rank Minimization Algorithms
	1. General Considerations}},
  journal = {IMA J Appl Math},
  year = {1970},
  volume = {6},
  pages = {76--90},
  number = {1},
  month = mar,
  abstract = {{This paper presents a more detailed analysis of a class of minimization
	algorithms, which includes as a special case the DFP (Davidon-Fletcher-Powell)
	method, than has previously appeared. Only quadratic functions are
	considered but particular attention is paid to the magnitude of successive
	errors and their dependence upon the initial matrix. On the basis
	of this a possible explanation of some of the observed characteristics
	of the class is tentatively suggested. 10.1093/imamat/6.1.76}},
  citeulike-article-id = {2945939},
  citeulike-linkout-0 = {http://dx.doi.org/10.1093/imamat/6.1.76},
  citeulike-linkout-1 = {http://imamat.oxfordjournals.org/cgi/content/abstract/6/1/76},
  day = {1},
  doi = {10.1093/imamat/6.1.76},
  posted-at = {2008-06-30 22:48:42},
  priority = {1},
  url = {http://dx.doi.org/10.1093/imamat/6.1.76}
}

@ARTICLE{Cauchy1847,
  author = {Cauchy, Augustin-Louis},
  title = {{M\'{e}thode g\'{e}n\'{e}rale pour la r\'{e}solution des syst\`{e}mes
	d'\'{e}quations simultan\'{e}es}},
  journal = {Compte Rendu des S'eances de L'Acad'emie des Sciences XXV},
  year = {1847},
  volume = {S'erie A},
  pages = {536--538},
  number = {25},
  month = oct,
  citeulike-article-id = {7133110},
  day = {18},
  keywords = {first, steepest-descent},
  posted-at = {2010-05-07 01:16:11},
  priority = {2}
}

@MANUAL{Cortes2011,
  title = {{Package `adabag'}},
  author = {Esteban Alfaro Cortes and Matias Gamez Martinez and Noelia Garcia
	Rubio},
  month = {October},
  year = {2011},
  owner = {brownlee},
  timestamp = {2011.12.12},
  url = {http://cran.r-project.org/web/packages/adabag/adabag.pdf}
}

@BOOK{Crawley2007,
  title = {The R Book},
  publisher = {Wiley},
  year = {2007},
  author = {Michael J. Crawley},
  owner = {jasonb},
  timestamp = {2011.12.24}
}

@ARTICLE{Culp2006,
  author = {Mark Culp and Kjell Johnson and George Michailides},
  title = {ada: An R Package for Stochastic Boosting},
  journal = {Journal of Statistical Software},
  year = {2006},
  volume = {17},
  pages = {1--27},
  number = {2},
  month = {9},
  accepted = {2007-07-13},
  bibdate = {2007-07-13},
  coden = {JSSOBK},
  day = {26},
  issn = {1548-7660},
  submitted = {2005-07-13},
  url = {http://www.jstatsoft.org/v17/i02}
}

@MANUAL{Culp2007,
  title = {{Package `ada'}},
  author = {Mark Culp and Kjell Johnson and George Michailidis},
  month = {November},
  year = {2007},
  owner = {brownlee},
  timestamp = {2011.12.12},
  url = {http://cran.r-project.org/web/packages/ada/ada.pdf}
}

@ARTICLE{Curry1944,
  author = {Haskell B. Curry},
  title = {The Method of Steepest Descent for Non-linear Minimization Problems},
  journal = {Quart. Appl. Math.},
  year = {1944},
  volume = {2},
  pages = {258--261},
  owner = {jasonb},
  timestamp = {2011.12.27}
}

@INPROCEEDINGS{Dietterich2000,
  author = {Dietterich, Thomas G.},
  title = {Ensemble Methods in Machine Learning},
  booktitle = {Proceedings of the First International Workshop on Multiple Classifier
	Systems},
  year = {2000},
  series = {MCS '00},
  pages = {1--15},
  address = {London, UK},
  publisher = {Springer-Verlag},
  acmid = {743935},
  isbn = {3-540-67704-6},
  numpages = {15},
  url = {http://dl.acm.org/citation.cfm?id=648054.743935}
}

@TECHREPORT{Dietterich1995,
  author = {Dietterich, T. G., and Kong, E. B.},
  title = {Machine Learning Bias, Statistical Bias, and Statistical Variance
	of Decision Tree Algorithms},
  institution = {Department of Computer Science, Oregon State University},
  year = {1995},
  address = {Corvallis, Oregon},
  owner = {brownlee},
  timestamp = {2011.11.24}
}

@BOOK{Duda2001,
  title = {Pattern Classification},
  publisher = {John Wiley and Sons, Inc.},
  year = {2001},
  author = {R. O. Duda and P. E. Hart and D. G. Stork},
  edition = {Second},
  owner = {brownlee},
  timestamp = {2011.02.09}
}

@ARTICLE{Fayyad1996a,
  author = {U. Fayyad and G. Piatetsky--Shapiro and P. Smyth},
  title = {From Data Mining to Knowledge Discovery in Databases},
  journal = {AI Mag},
  year = {1996},
  volume = {17},
  number = {3},
  owner = {brownlee},
  timestamp = {2011.02.09}
}

@ARTICLE{Fletcher1970,
  author = {Fletcher, R.},
  title = {{A new approach to variable metric algorithms}},
  journal = {The Computer Journal},
  year = {1970},
  volume = {13},
  pages = {317--322},
  number = {3},
  month = mar,
  abstract = {{An approach to variable metric algorithms has been investigated in
	which the linear search sub-problem no longer becomes necessary.
	The property of quadratic termination has been replaced by one of
	monotonic convergence of the eigenvalues of the approximating matrix
	to the inverse hessian. A convex class of updating formulae which
	possess this property has been established, and a strategy has been
	indicated for choosing a member of the class so as to keep the approximation
	away from both singularity and unboundedness. A FORTRAN program has
	been tested extensively with encouraging results. 10.1093/comjnl/13.3.317}},
  citeulike-article-id = {7133130},
  citeulike-linkout-0 = {http://dx.doi.org/10.1093/comjnl/13.3.317},
  day = {1},
  doi = {10.1093/comjnl/13.3.317},
  keywords = {bfgs},
  posted-at = {2010-05-07 01:16:26},
  priority = {2},
  url = {http://dx.doi.org/10.1093/comjnl/13.3.317}
}

@ARTICLE{Fletcher1964,
  author = {Fletcher, R and Reeves, C M},
  title = {Function minimization by conjugate gradients},
  journal = {The Computer Journal},
  year = {1964},
  volume = {7},
  pages = {149--154},
  number = {2},
  publisher = {Br Computer Soc},
  url = {http://comjnl.oupjournals.org/cgi/doi/10.1093/comjnl/7.2.149}
}

@BOOK{Foulkes2009,
  title = {Applied Statistical Genetics with {R}: For Population-Based Association
	Studies},
  publisher = {Springer},
  year = {2009},
  author = {Andrea S. Foulkes},
  series = {Use R},
  abstract = {In this introductory graduate level text, Dr.~Foulkes elucidates core
	concepts that undergird the wide range of analytic techniques and
	software tools for the analysis of data derived from population-based
	genetic investigations. Applied Statistical Genetics with R offers
	a clear and cogent presentation of several fundamental statistical
	approaches that researchers from multiple disciplines, including
	medicine, public health, epidemiology, statistics and computer science,
	will find useful in exploring this emerging field.},
  isbn = {978-0-387-89553-6},
  orderinfo = {springer.txt},
  publisherurl = {http://www.springeronline.com/978-0-387-89553-6}
}

@ARTICLE{Frawley1992,
  author = {W. J. Frawley and G. Piatetsky--Shapiro and C. J. Matheus},
  title = {Knowledge Discovery in Databases: An Overview},
  journal = {AI Mag},
  year = {1992},
  volume = {13},
  number = {3},
  owner = {brownlee},
  timestamp = {2011.02.09}
}

@ARTICLE{Freund1999,
  author = {Freund, Y. and Schapire, R.},
  title = {{A short introduction to boosting}},
  journal = {J. Japan. Soc. for Artif. Intel.},
  year = {1999},
  volume = {14},
  pages = {771--780},
  number = {5},
  citeulike-article-id = {1626752},
  citeulike-linkout-0 = {\#},
  posted-at = {2007-09-06 15:12:38},
  priority = {0},
  url = {citeseer.ist.psu.edu/freund99short.html}
}

@ARTICLE{Freund1997,
  author = {Yoav Freund and Robert E. Schapire},
  title = {A Decision--Theoretic Generalization of On--Line Learning and an
	Application to Boosting},
  journal = {Journal of Computer and System Sciences},
  year = {1997},
  volume = {55},
  pages = {119--139},
  number = {1},
  doi = {10.1006/jcss.1997.1504},
  issn = {0022-0000},
  url = {http://www.sciencedirect.com/science/article/pii/S002200009791504X}
}

@MANUAL{Friedman2011,
  title = {{Package `glmnet'}: Lasso and elastic-net regularized generalized
	linear models},
  author = {Jerome Friedman and Trevor Hastie and Rob Tibshirani},
  year = {2011},
  owner = {brownlee},
  timestamp = {2011.12.13},
  url = {http://cran.r-project.org/web/packages/glmnet/glmnet.pdf}
}

@ARTICLE{Friedman2001,
  author = {Friedman, Jerome H.},
  title = {{Greedy function approximation: A gradient boosting machine}},
  journal = {Annals of Statistics},
  year = {2001},
  volume = {29},
  pages = {1189--1232},
  abstract = {{Function approximation is viewed from the perspective of numerical
	optimization in function space, rather than parameter space. A connection
	is made between stagewise additive expansions and steepest--descent
	minimization. A general gradient--descent \&amp;quot;boosting\&amp;quot;
	paradigm is developed for additive expansions based on any fitting
	criterion. Specific algorithms are presented for least--squares,
	least--absolute--deviation, and Huber--M loss functions for regression,
	and multi--class logistic likelihood for classification. Special
	enhancements are derived for the particular case where the individual
	additive components are decision trees, and tools for interpreting
	such \&amp;quot;TreeBoost \&amp;quot; models are presented. Gradient
	boosting of decision trees produces competitive, highly robust, interpretable
	procedures for regression and classification, especially appropriate
	for mining less than clean data. Connections between this approach
	and the boosting methods of Freund and Shapire 1996, and Friedman,
	Hastie, and Tibshirani 1998 are discussed.}},
  citeulike-article-id = {3154111},
  citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.31.869},
  posted-at = {2008-08-25 20:40:24},
  priority = {2},
  url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.31.869}
}

@ARTICLE{Friedman1991,
  author = {Friedman, Jerome H.},
  title = {{Multivariate Adaptive Regression Splines}},
  journal = {The Annals of Statistics},
  year = {1991},
  volume = {19},
  pages = {1--67},
  number = {1},
  abstract = {{A new method is presented for flexible regression modeling of high
	dimensional data. The model takes the form of an expansion in product
	spline basis functions, where the number of basis functions as well
	as the parameters associated with each one (product degree and knot
	locations) are automatically determined by the data. This procedure
	is motivated by the recursive partitioning approach to regression
	and shares its attractive properties. Unlike recursive partitioning,
	however, this method produces continuous models with continuous derivatives.
	It has more power and flexibility to model relationships that are
	nearly additive or involve interactions in at most a few variables.
	In addition, the model can be represented in a form that separately
	identifies the additive contributions and those associated with the
	different multivariable interactions.}},
  citeulike-article-id = {4371368},
  citeulike-linkout-0 = {http://dx.doi.org/10.2307/2241837},
  citeulike-linkout-1 = {http://www.jstor.org/stable/2241837},
  doi = {10.2307/2241837},
  issn = {00905364},
  keywords = {nonparametric\_regression, statistics},
  posted-at = {2009-04-21 09:08:01},
  priority = {2},
  publisher = {Institute of Mathematical Statistics},
  url = {http://dx.doi.org/10.2307/2241837}
}

@BOOK{Fukunaga1990,
  title = {Introduction to Statistical Pattern Recognition},
  publisher = {Academic Press},
  year = {1990},
  author = {K. Fukunaga},
  edition = {Second},
  owner = {jbrownlee},
  timestamp = {2008.03.04}
}

@ARTICLE{Goldfarb1970,
  author = {Goldfarb, D.},
  title = {{A Family of Variable Metric Updates Derived by Variational Means}},
  journal = {Mathematics of Computation},
  year = {1970},
  volume = {24},
  pages = {23--26},
  citeulike-article-id = {8491642},
  posted-at = {2010-12-29 19:26:05},
  priority = {2}
}

@BOOK{Griva2009,
  title = {Linear and nonlinear optimization},
  publisher = {Society for Industrial and Applied Mathematics},
  year = {2009},
  author = {Griva, I. and Nash, S.G. and Sofer, A.},
  isbn = {9780898716610},
  lccn = {2008032477},
  url = {http://books.google.com.au/books?id=uOJ-Vg1BnKgC}
}

@MANUAL{Hastie2011,
  title = {{Package `lars'}: Least Angle Regression, Lasso and Forward Stagewise},
  author = {Trevor Hastie and Brad Efron},
  month = {March},
  year = {2011},
  owner = {brownlee},
  timestamp = {2011.12.13},
  url = {http://cran.r-project.org/web/packages/lars/lars.pdf}
}

@BOOK{Hastie2009,
  title = {The Elements of Statistical Learning: Data Mining, Inference, and
	Prediction},
  publisher = {Springer},
  year = {2009},
  author = {T. Hastie and R. Tibshirani and J. Friedman},
  edition = {Second},
  owner = {brownlee},
  timestamp = {2011.02.08}
}

@BOOK{Heath2002,
  title = {Scientific computing: an introductory survey},
  publisher = {McGraw-Hill},
  year = {2002},
  author = {Michael T. Heath},
  owner = {jasonb},
  timestamp = {2011.12.26}
}

@ARTICLE{Hocking1976,
  author = {Hocking, R R},
  title = {The Analysis and Selection of Variables in Linear Regression},
  journal = {Biometrics},
  year = {1976},
  volume = {32},
  pages = {1--49},
  number = {1},
  url = {http://www.jstor.org/stable/2529336}
}

@BOOK{Hosmer2000,
  title = {Applied logistic regression},
  publisher = {Wiley},
  year = {2000},
  author = {Hosmer, D.W. and Lemeshow, S.},
  series = {Wiley series in probability and statistics: Texts and references
	section},
  isbn = {9780471356325},
  lccn = {00036843},
  url = {http://books.google.com.au/books?id=DEtar8K5ASsC}
}

@TECHREPORT{Johnson1955,
  author = {S. M. Johnson},
  title = {Best exploration for maximum is Fibonaccian},
  institution = {RAND Corporation},
  year = {1955},
  type = {Research Memoranda},
  number = {RM--1590},
  address = {Santa Monica, Calif},
  month = {November},
  publisher = {Rand Corporation},
  url = {http://books.google.com.au/books?id=3uJ0HAAACAAJ}
}

@ARTICLE{Karatzoglou2006,
  author = {Alexandros Karatzoglou and David Meyer and Kurt Hornik},
  title = {Support Vector Machines in R},
  journal = {Journal of Statistical Software},
  year = {2006},
  volume = {15},
  pages = {1--28},
  number = {9},
  month = {4},
  accepted = {2006-04-06},
  bibdate = {2006-04-06},
  coden = {JSSOBK},
  day = {6},
  issn = {1548-7660},
  submitted = {2005-10-24},
  url = {http://www.jstatsoft.org/v15/i09}
}

@BOOK{Kearns1994,
  title = {An introduction to computational learning theory},
  publisher = {MIT Press},
  year = {1994},
  author = {M. J. Kearns and U. V. Vazirani},
  owner = {brownlee},
  timestamp = {2011.02.09}
}

@ARTICLE{Kiefer1953,
  author = {J. Kiefer},
  title = {Sequential minimax search for a maximum},
  journal = {Proceedings of the American Mathematical Society},
  year = {1953},
  volume = {4},
  pages = {502--506},
  number = {3},
  owner = {jasonb},
  timestamp = {2011.12.27}
}

@BOOK{Kleinbaum2010,
  title = {Logistic Regression: A Self-Learning Text},
  publisher = {Springer},
  year = {2010},
  author = {Kleinbaum, D.G. and Klein, M. and Pryor, E.R.},
  series = {Statistics for Biology and Health},
  isbn = {9781441917416},
  lccn = {2009943538},
  url = {http://books.google.com.au/books?id=J7E0JQweHkoC}
}

@TECHREPORT{Komarek2005,
  author = {Paul Komarek and Andrew Moore},
  title = {Making Logistic Regression A Core Data Mining Tool: A Practical Investigation
	of Accuracy, Speed, and Simplicity},
  institution = {Robotics Institute, Carnegie Mellon University},
  year = {2005},
  number = {CMU-RI-TR-05-27},
  address = {Pittsburgh, PA},
  month = {May},
  howpublished = {technical report},
  pages = {13},
  volume = {TR-05-27}
}

@MANUAL{Kuhn2011,
  title = {{Package `caret'}},
  author = {Max Kuhn},
  month = {December},
  year = {2011},
  owner = {brownlee},
  timestamp = {2011.12.12},
  url = {http://cran.r-project.org/web/packages/caret/caret.pdf}
}

@ARTICLE{Lagarias1998,
  author = {Lagarias, Jeffrey C. and Reeds, James A. and Wright, Margaret H.
	and Wright, Paul E.},
  title = {Convergence Properties of the Nelder--Mead Simplex Method in Low
	Dimensions},
  journal = {SIAM J. on Optimization},
  year = {1998},
  volume = {9},
  pages = {112--147},
  month = {May},
  acmid = {589108},
  address = {Philadelphia, PA, USA},
  doi = {http://dx.doi.org/10.1137/S1052623496303470},
  issn = {1052-6234},
  issue = {1},
  keywords = {Nelder--Mead simplex methods, direct search methods, nonderivative
	optimization},
  numpages = {36},
  publisher = {Society for Industrial and Applied Mathematics},
  url = {http://dx.doi.org/10.1137/S1052623496303470}
}

@ARTICLE{Liaw2002,
  author = {Andy Liaw and Matthew Wiener},
  title = {Classiﬁcation and Regression by randomForest},
  journal = {R News},
  year = {2002},
  volume = {2},
  pages = {18--22},
  number = {3},
  month = {December},
  owner = {brownlee},
  timestamp = {2011.12.09}
}

@ARTICLE{Long2010,
  author = {Long, Philip M. and Servedio, Rocco A.},
  title = {Random classification noise defeats all convex potential boosters},
  journal = {Mach. Learn.},
  year = {2010},
  volume = {78},
  pages = {287--304},
  month = {March},
  acmid = {1713653},
  address = {Hingham, MA, USA},
  doi = {http://dx.doi.org/10.1007/s10994-009-5165-z},
  issn = {0885-6125},
  issue = {3},
  keywords = {Boosting, Convex loss, Learning theory, Misclassification noise, Noise-tolerant
	learning, Potential boosting},
  numpages = {18},
  publisher = {Kluwer Academic Publishers},
  url = {http://dx.doi.org/10.1007/s10994-009-5165-z}
}

@BOOK{Luger1993,
  title = {Artificial Intelligence: Structures and Strategies for Complex Problem
	Solving},
  publisher = {Benjamin/Cummings Pub. Co.},
  year = {1993},
  author = {G. F. Luger and W. A. Stubblefield},
  edition = {Second},
  owner = {jasonb},
  timestamp = {2010.01.13}
}

@BOOK{MacKay2003,
  title = {Information theory, inference, and learning algorithms},
  publisher = {Cambridge University Press},
  year = {2003},
  author = {D. J. C. MacKay},
  owner = {brownlee},
  timestamp = {2011.02.09}
}

@BOOK{Matloff2011,
  title = {The Art of R Programming: A Tour of Statistical Software Design},
  publisher = {No Starch Press},
  year = {2011},
  author = {Norman Matloff},
  owner = {jasonb},
  timestamp = {2011.12.24}
}

@ARTICLE{Mease2008,
  author = {Mease, David and Wyner, Abraham},
  title = {{Evidence Contrary to the Statistical View of Boosting}},
  journal = {J. Mach. Learn. Res.},
  year = {2008},
  volume = {9},
  pages = {131--156},
  abstract = {{The statistical perspective on boosting algorithms focuses on optimization,
	drawing parallels with maximum likelihood estimation for logistic
	regression. In this paper we present empirical evidence that raises
	questions about this view. Although the statistical perspective provides
	a theoretical framework within which it is possible to derive theorems
	and create new algorithms in general contexts, we show that there
	remain many unanswered important questions. Furthermore, we provide
	examples that reveal crucial flaws in the many practical suggestions
	and new methods that are derived from the statistical view. We perform
	carefully designed experiments using simple simulation models to
	illustrate some of these flaws and their practical consequences.}},
  address = {Cambridge, MA, USA},
  citeulike-article-id = {5128162},
  citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1390681.1390687},
  issn = {1532-4435},
  keywords = {boosting, machine\_learning, simulation, statistics},
  posted-at = {2009-07-12 19:15:25},
  priority = {2},
  publisher = {JMLR.org},
  url = {http://portal.acm.org/citation.cfm?id=1390681.1390687}
}

@MANUAL{Meier2009,
  title = {{Package `grplasso'}: Fitting user speciﬁed models with Group Lasso
	penalty},
  author = {Lukas Meier},
  year = {2009},
  owner = {brownlee},
  timestamp = {2011.12.13},
  url = {http://cran.r-project.org/web/packages/grplasso/grplasso.pdf}
}

@INBOOK{Meir2003,
  pages = {118--183},
  title = {An introduction to boosting and leveraging},
  publisher = {Springer-Verlag New York, Inc.},
  year = {2003},
  author = {Meir, Ron and R\"{a}tsch, Gunnar},
  address = {New York, NY, USA},
  acmid = {863719},
  book = {Advanced lectures on machine learning},
  isbn = {3-540-00529-3},
  numpages = {66},
  url = {http://dl.acm.org/citation.cfm?id=863714.863719}
}

@TECHREPORT{Meyer2011,
  author = {David Meyer},
  title = {Support Vector Machines: The Interface to libsvm in package e1071},
  institution = {Technische Universitat Wien, Austria},
  year = {2011},
  owner = {brownlee},
  timestamp = {2011.12.06}
}

@ARTICLE{Mills2010,
  author = {Mills, Josh},
  title = {Estimation of Statistical Models in R},
  journal = {Syntax},
  year = {2010},
  pages = {1--145}
}

@TECHREPORT{Mitchell2006,
  author = {T. Mitchell},
  title = {The Discipline of Machine Learning},
  institution = {School of Computer Science, Carnegie Mellon University},
  year = {2006},
  number = {CMU-ML-06-108},
  month = {July},
  owner = {brownlee},
  timestamp = {2011.02.08}
}

@BOOK{Mitchell1997,
  title = {Machine Learning},
  publisher = {McGraw-Hill},
  year = {1997},
  author = {T. M. Mitchell},
  owner = {brownlee},
  timestamp = {2011.02.08}
}

@ARTICLE{Mundry2009,
  author = {Mundry, Roger and Nunn, Charles L},
  title = {Stepwise model fitting and statistical inference: turning noise into
	signal pollution.},
  journal = {The American naturalist},
  year = {2009},
  volume = {173},
  pages = {119--23},
  number = {1},
  publisher = {UChicago Press},
  url = {http://www.ncbi.nlm.nih.gov/pubmed/19049440}
}

@ARTICLE{Nelder1965,
  author = {Nelder, J. A. and Mead, R.},
  title = {{A Simplex Method for Function Minimization}},
  journal = {The Computer Journal},
  year = {1965},
  volume = {7},
  pages = {308--313},
  number = {4},
  month = jan,
  abstract = {{A method is described for the minimization of a function of n variables,
	which depends on the comparison of function values at the (n + 1)
	vertices of a general simplex, followed by the replacement of the
	vertex with the highest value by another point. The simplex adapts
	itself to the local landscape, and contracts on to the final minimum.
	The method is shown to be effective and computationally compact.
	A procedure is given for the estimation of the Hessian matrix in
	the neighbourhood of the minimum, needed in statistical estimation
	problems.}},
  citeulike-article-id = {3009487},
  citeulike-linkout-0 = {http://dx.doi.org/10.1093/comjnl/7.4.308},
  citeulike-linkout-1 = {http://comjnl.oxfordjournals.org/content/7/4/308.abstract},
  citeulike-linkout-2 = {http://comjnl.oxfordjournals.org/content/7/4/308.full.pdf},
  citeulike-linkout-3 = {http://comjnl.oxfordjournals.org/cgi/content/abstract/7/4/308},
  day = {1},
  doi = {10.1093/comjnl/7.4.308},
  posted-at = {2008-09-15 16:23:09},
  priority = {2},
  url = {http://dx.doi.org/10.1093/comjnl/7.4.308}
}

@ARTICLE{Overholt1965,
  author = {K. J. Overholt},
  title = {An instability in the Fibonacci and golden section search methods},
  journal = {BIT},
  year = {1965},
  volume = {5},
  pages = {284},
  owner = {jasonb},
  timestamp = {2011.12.26}
}

@BOOK{Pampel2000,
  title = {Logistic regression: a primer},
  publisher = {Sage Publications},
  year = {2000},
  author = {Pampel, F.C.},
  series = {Sage university papers series: Quantitative applications in the social
	sciences},
  isbn = {9780761920106},
  lccn = {00008060},
  url = {http://books.google.com.au/books?id=lfzSqxFceq0C}
}

@ARTICLE{Peduzzi1996,
  author = {Peduzzi, Peter and Concato, John and Kemper, Elizabeth and Holford,
	Theodore R. and Feinstein, Alvan R.},
  title = {{A simulation study of the number of events per variable in logistic
	regression analysis}},
  journal = {Journal of Clinical Epidemiology},
  year = {1996},
  volume = {49},
  pages = {1373--1379},
  number = {12},
  month = dec,
  abstract = {{We performed a Monte Carlo study to evaluate the effect of the number
	of events per variable (EPV) analyzed in logistic regression analysis.
	The simulations were based on data from a cardiac trial of 673 patients
	in which 252 deaths occurred and seven variables were cogent predictors
	of mortality; the number of events per predictive variable was ()
	for the full sample. For the simulations, at values of EPV = 2, 5,
	10, 15, 20, and 25, we randomly generated 500 samples of the 673
	patients, chosen with replacement, according to a logistic model
	derived from the full sample. Simulation results for the regression
	coefficients for each variable in each group of 500 samples were
	compared for bias, precision, and significance testing against the
	results of the model fitted to the original sample. For EPV values
	of 10 or greater, no major problems occurred. For EPV values less
	than 10, however, the regression coefficients were biased in both
	positive and negative directions; the large sample variance estimates
	from the logistic model both overestimated and underestimated the
	sample variance of the regression coeffi-cients; the 90\% confidence
	limits about the estimated values did not have proper coverage; the
	Wald statistic was conservative under the null hypothesis; and paradoxical
	associations (significance in the wrong direction) were increased.
	Although other factors (such as the total number of events, or sample
	size) may influence the validity of the logistic model, our findings
	indicate that low EPV can lead to major problems.}},
  citeulike-article-id = {2305744},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/S0895-4356(96)00236-3},
  citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0895-4356(96)00236-3},
  citeulike-linkout-2 = {http://www.sciencedirect.com/science/article/B6T84-3W30X5C-8/2/f1b4e237713e6d272e85c988556f1d4e},
  doi = {10.1016/S0895-4356(96)00236-3},
  issn = {08954356},
  keywords = {logistic, model\_selection, power},
  posted-at = {2011-03-24 19:17:32},
  priority = {2},
  url = {http://dx.doi.org/10.1016/S0895-4356(96)00236-3}
}

@MANUAL{Peters2011,
  title = {{Package `ipred'}},
  author = {Andrea Peters and Torsten Hothorn},
  month = {February},
  year = {2011},
  owner = {brownlee},
  timestamp = {2011.12.12},
  url = {http://cran.r-project.org/web/packages/ipred/ipred.pdf}
}

@MANUAL{Peters2011a,
  title = {{ipred: Improved Predictors}},
  author = {Andrea Peters and Torsten Hothorn},
  year = {2011},
  owner = {brownlee},
  timestamp = {2011.12.12},
  url = {http://cran.r-project.org/web/packages/ipred/vignettes/ipred-examples.pdf}
}

@INBOOK{Press2007,
  chapter = {Section 10.2. Golden Section Search in One Dimension},
  pages = {492--495},
  title = {Numerical Recipes: The Art of Scientific Computing},
  publisher = {Cambridge University Press},
  year = {2007},
  author = {William H. Press and Saul A. Teukolsky and William T. Vetterling
	and Brian P. Flannery},
  owner = {jasonb},
  timestamp = {2011.12.26}
}

@BOOK{Quinlan1993,
  title = {C4.5: Programs for Machine Learning},
  publisher = {Morgan Kaufmann},
  year = {1993},
  author = {J. R. Quinlan},
  owner = {brownlee},
  timestamp = {2011.11.23}
}

@MANUAL{RDevelopmentCoreTeam2011,
  title = {R: A Language and Environment for Statistical Computing},
  author = {{R Development Core Team}},
  organization = {R Foundation for Statistical Computing},
  address = {Vienna, Austria},
  year = {2011},
  note = {{ISBN} 3-900051-07-0},
  url = {http://www.R-project.org}
}

@BOOK{Reed1998,
  title = {Neural Smithing: Supervised Learning in Feedforward Artificial Neural
	Networks},
  publisher = {MIT Press},
  year = {1998},
  author = {Reed, Russell D. and Marks, Robert J.},
  address = {Cambridge, MA, USA},
  isbn = {0262181908}
}

@MANUAL{Ridgeway2007,
  title = {{Generalized Boosted Models: A guide to the gbm package}},
  author = {Greg Ridgeway},
  month = {August},
  year = {2007},
  citeulike-article-id = {7678599},
  citeulike-linkout-0 = {http://cran.r-project.org/web/packages/gbm/vignettes/gbm.pdf},
  keywords = {boosting},
  posted-at = {2010-08-19 02:48:26},
  priority = {2},
  url = {http://cran.r-project.org/web/packages/gbm/vignettes/gbm.pdf}
}

@MANUAL{Ridgeway2007a,
  title = {{Package `gbm'}},
  author = {Greg Ridgeway},
  month = {August},
  year = {2007},
  owner = {brownlee},
  timestamp = {2011.12.12},
  url = {http://cran.r-project.org/web/packages/gbm/gbm.pdf}
}

@BOOK{Russell2009,
  title = {Artificial Intelligence: A Modern Approach},
  publisher = {Prentice Hall},
  year = {2009},
  author = {S. Russell and P. Norvig},
  edition = {Third},
  owner = {jasonb},
  timestamp = {2010.01.13}
}

@ARTICLE{Shanno1970,
  author = {Shanno, D. F.},
  title = {{Conditioning of Quasi-Newton Methods for Function Minimization}},
  journal = {Mathematics of Computation},
  year = {1970},
  volume = {24},
  pages = {647--656},
  number = {111},
  month = jul,
  abstract = {{Quasi-Newton methods accelerate the steepest-descent technique for
	function minimization by using computational history to generate
	a sequence of approximations to the inverse of the Hessian matrix.
	This paper presents a class of approximating matrices as a function
	of a scalar parameter. The problem of optimal conditioning of these
	matrices under an appropriate norm as a function of the scalar parameter
	is investigated. A set of computational results verifies the superiority
	of the new methods arising from conditioning considerations to known
	methods.}},
  citeulike-article-id = {4267226},
  citeulike-linkout-0 = {http://dx.doi.org/10.2307/2004840},
  citeulike-linkout-1 = {http://www.jstor.org/stable/2004840},
  doi = {10.2307/2004840},
  issn = {00255718},
  keywords = {qbo\_nlpca2c},
  posted-at = {2009-04-03 02:28:35},
  priority = {2},
  publisher = {American Mathematical Society},
  url = {http://dx.doi.org/10.2307/2004840}
}

@TECHREPORT{Shewchuk1994,
  author = {Shewchuk, Jonathan R.},
  title = {{An Introduction to the Conjugate Gradient Method Without the Agonizing
	Pain}},
  year = {1994},
  address = {Pittsburgh, PA, USA},
  citeulike-article-id = {264342},
  citeulike-linkout-0 = {http://www.cs.cmu.edu/\~{}quake-papers/painless-conjugate-gradient.pdf},
  citeulike-linkout-1 = {http://portal.acm.org/citation.cfm?id=865018},
  keywords = {optimization},
  posted-at = {2007-10-09 14:30:47},
  priority = {2},
  publisher = {Carnegie Mellon University},
  url = {http://www.cs.cmu.edu/\~{}quake-papers/painless-conjugate-gradient.pdf}
}

@ARTICLE{Spang1962,
  author = {H. A. Spang},
  title = {{A Review of Minimization Techniques for Nonlinear Functions}},
  journal = {SIAM Review},
  year = {1962},
  volume = {4},
  pages = {343--365},
  number = {4},
  citeulike-article-id = {6904218},
  citeulike-linkout-0 = {http://www.ams.org/mathscinet-getitem?mr=26:3171},
  posted-at = {2010-03-25 06:09:33},
  priority = {2},
  url = {http://www.ams.org/mathscinet-getitem?mr=26:3171}
}

@ARTICLE{Spendley1962,
  author = {Spendley, W. and Hext, G. R. and Himsworth, F. R.},
  title = {{Sequential Application of Simplex Designs in Optimization and Evolutionary
	Operation}},
  journal = {Technometrics},
  year = {1962},
  volume = {4},
  pages = {441--461},
  citeulike-article-id = {2846890},
  keywords = {dfo, optimisation, simplex},
  posted-at = {2008-05-30 10:37:13},
  priority = {2}
}

@ARTICLE{Strobl2009,
  author = {Carolin Strobl and Torsten Hothorn and Achim Zeileis},
  title = {Party on! A New, Conditional Variable-Importance Measure for Random
	Forests Available in the party Package},
  journal = {The R Journal},
  year = {2009},
  volume = {1/2},
  pages = {14--17},
  owner = {brownlee},
  timestamp = {2011.12.09}
}

@BOOK{Sutton1998,
  title = {Reinforcement Learning: An Introduction},
  publisher = {MIT Press},
  year = {1998},
  author = {R. Sutton and A. Bardo},
  owner = {brownlee},
  timestamp = {2011.02.09}
}

@ARTICLE{Tibshirani1996,
  author = {Tibshirani, Robert},
  title = {{Regression shrinkage and selection via the lasso}},
  journal = {J. Roy. Statist. Soc. Ser. B},
  year = {1996},
  volume = {58},
  pages = {267--288},
  number = {1},
  abstract = {{We propose a new method for estimation in linear models. The \&quot;lasso\&quot;
	minimizes the residual sum of squares subject to the sum of the absolute
	value of the coefficients being less than a constant. Because of
	the nature of this constraint it tends to produce some coefficients
	that are exactly zero and hence gives interpretable models. Our simulation
	studies suggest that the lasso enjoys some of the favourable properties
	of both subset selection and ridge regression. It produces interpretable
	models like subset selection and exhibits the stability of ridge
	regression. There is also an interesting relationship with recent
	work in adaptive function estimation by Donoho and Johnstone. The
	lasso idea is quite general and can be applied in a variety of statistical
	models: extensions to generalized regression models}},
  citeulike-article-id = {416068},
  citeulike-linkout-0 = {http://www.ams.org/mathscinet-getitem?mr=1379242},
  keywords = {feature-selection, lasso, regression, ridge-regression, shrinkage},
  mrnumber = {MR1379242},
  posted-at = {2008-11-13 17:23:13},
  priority = {3},
  url = {http://www.ams.org/mathscinet-getitem?mr=1379242}
}

@TECHREPORT{Tibshirani1996a,
  author = {Tibshirani, R.},
  title = {{Bias, Variance, and Prediction Error for Classification Rules}},
  institution = {Department of Statistics, University of Toronto},
  year = {1996},
  citeulike-article-id = {340511},
  keywords = {biasvariance, diplomarbeit},
  posted-at = {2005-10-04 12:14:09},
  priority = {0}
}

@BOOK{Torgo2009,
  title = {Data Mining with R},
  publisher = {CRC Press},
  year = {2009},
  author = {Torgo, Luís},
  added-at = {2009-01-22T17:32:38.000+0100},
  biburl = {http://www.bibsonomy.org/bibtex/23a150daaf62344685dd63088a995a9c5/tmalsburg},
  description = {The main goal of this book is to introduce the reader to the use of
	R as a tool for performing data mining.},
  interhash = {427fb0ce49a4101586b5855df045fce5},
  intrahash = {3a150daaf62344685dd63088a995a9c5},
  keywords = {book datamining gnu-r introduction neuralnetworks statistics trading},
  timestamp = {2009-01-22T17:32:38.000+0100}
}

@BOOK{Walters1991,
  title = {Sequential simplex optimization: a technique for improving quality
	and productivity in research, development, and manufacturing},
  publisher = {CRC Press},
  year = {1991},
  author = {Walters, F.H.},
  series = {Chemometrics series},
  isbn = {9780849358944},
  lccn = {91014187},
  url = {http://books.google.com.au/books?id=hpxTAAAAMAAJ}
}

@ARTICLE{Whittingham2006,
  author = {Whittingham, Mark J. and Stephens, Philip A. and Bradbury, Richard
	B. and Freckleton, Robert P.},
  title = {{Why do we still use stepwise modelling in ecology and behaviour?}},
  journal = {Journal of Animal Ecology},
  year = {2006},
  volume = {75},
  pages = {1182--1189},
  number = {5},
  month = sep,
  abstract = {{Summary * 1The biases and shortcomings of stepwise multiple regression
	are well established within the statistical literature. However,
	an examination of papers published in 2004 by three leading ecological
	and behavioural journals suggested that the use of this technique
	remains widespread: of 65 papers in which a multiple regression approach
	was used, 57\% of studies used a stepwise procedure. * 2The principal
	drawbacks of stepwise multiple regression include bias in parameter
	estimation, inconsistencies among model selection algorithms, an
	inherent (but often overlooked) problem of multiple hypothesis testing,
	and an inappropriate focus or reliance on a single best model. We
	discuss each of these issues with examples. * 3We use a worked example
	of data on yellowhammer distribution collected over 4 years to highlight
	the pitfalls of stepwise regression. We show that stepwise regression
	allows models containing significant predictors to be obtained from
	each year's data. In spite of the significance of the selected models,
	they vary substantially between years and suggest patterns that are
	at odds with those determined by analysing the full, 4-year data
	set. * 4An information theoretic (IT) analysis of the yellowhammer
	data set illustrates why the varying outcomes of stepwise analyses
	arise. In particular, the IT approach identifies large numbers of
	competing models that could describe the data equally well, showing
	that no one model should be relied upon for inference.}},
  address = {Department of Mathematics, University of Bristol, University Walk,
	Bristol, BS8 1TW, UK; ; Royal Society for the Protection of Birds,
	The Lodge, Sandy, Bedfordshire, SG19 2DL, UK; and ; Department of
	Animal and Plant Sciences, University of Sheffield, Sheffield S10
	2TN, UK},
  citeulike-article-id = {786972},
  citeulike-linkout-0 = {http://www.blackwell-synergy.com/doi/abs/10.1111/j.1365-2656.2006.01141.x},
  citeulike-linkout-1 = {http://dx.doi.org/10.1111/j.1365-2656.2006.01141.x},
  citeulike-linkout-2 = {http://www.ingentaconnect.com/content/bsc/janim/2006/00000075/00000005/art00016},
  citeulike-linkout-3 = {http://view.ncbi.nlm.nih.gov/pubmed/16922854},
  citeulike-linkout-4 = {http://www.hubmed.org/display.cgi?uids=16922854},
  citeulike-linkout-5 = {http://www3.interscience.wiley.com/cgi-bin/abstract/118727122/ABSTRACT},
  doi = {10.1111/j.1365-2656.2006.01141.x},
  issn = {0021-8790},
  keywords = {plant\_ecology, statistics},
  pmid = {16922854},
  posted-at = {2009-03-23 10:12:31},
  priority = {2},
  publisher = {Blackwell Publishing Ltd},
  url = {http://dx.doi.org/10.1111/j.1365-2656.2006.01141.x}
}

@BOOK{Witten2011,
  title = {Data Mining: Practical Machine Learning Tools and Techniques},
  publisher = {Morgan Kaufmann Publishers},
  year = {2011},
  author = {I. H. Witten and E. Frank and M. A. Hall},
  edition = {Third},
  owner = {jasonb},
  timestamp = {2010.01.09}
}

@ARTICLE{Zhu1997,
  author = {Zhu, Ciyou and Byrd, Richard H. and Lu, Peihuang and Nocedal, Jorge},
  title = {Algorithm 778: L-BFGS-B: Fortran subroutines for large-scale bound-constrained
	optimization},
  journal = {ACM Trans. Math. Softw.},
  year = {1997},
  volume = {23},
  pages = {550--560},
  month = {December},
  acmid = {279236},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/279232.279236},
  issn = {0098-3500},
  issue = {4},
  issue_date = {Dec. 1997},
  keywords = {large-scale optimization, limited-memory method, nonlinear optimization,
	variable metric method},
  numpages = {11},
  publisher = {ACM},
  url = {http://doi.acm.org/10.1145/279232.279236}
}

@TECHREPORT{Zhu2008,
  author = {X. Zhu},
  title = {Semi-Supervised Learning Literature Survey},
  institution = {University of Wisconsin, Madison},
  year = {2008},
  number = {TR1530},
  owner = {brownlee},
  timestamp = {2011.02.10}
}

@BOOK{Zhu2009,
  title = {Introduction to Semi-Supervised Learning},
  publisher = {Morgan and Claypool Publishers},
  year = {2009},
  author = {X. Zhu and A. B. Goldberg},
  owner = {brownlee},
  timestamp = {2011.02.10}
}

@ARTICLE{Zou2005,
  author = {Hui Zou and Trevor Hastie},
  title = {Regularization and variable selection via the elastic net},
  journal = {Journal Of The Royal Statistical Society Series B},
  year = {2005},
  volume = {67},
  pages = {301-320},
  number = {2},
  abstract = {This study investigates the impact of the current financial crisis
	on Canada's potential GDP growth. Using a simple accounting framework
	to decompose trend GDP growth into changes in capital, labor services
	and total factor productivity, we find a sizeable drop in Canadian
	potential growth in the short term. The estimated decline of about
	1 percentage point originates from a sharply decelerating capital
	stock accumulation (as investment has dropped steeply) and a rising
	long-term unemployment rate (which would raise equilibrium unemployment
	rates). However, over the medium term, we expect Canada's potential
	GDP growth to gradually rise to around 2 percent, below the pre-crisis
	growth rate, mostly reflecting the effects of population aging and
	a secular decline in average working hours.},
  url = {http://ideas.repec.org/a/bla/jorssb/v67y2005i2p301-320.html}
}

@BOOK{Chapelle2010,
  title = {Semi-Supervised Learning},
  publisher = {The MIT Press},
  year = {2010},
  editor = {O. Chapelle and B. Sch\"olkopf and A. Zien},
  owner = {brownlee},
  timestamp = {2011.02.10}
}

